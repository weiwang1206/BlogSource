{"Asset":{"t270j8n8ybcn3c61":{"_id":"t270j8n8ybcn3c61","source":"themes\\light\\source\\fancybox\\blank.gif","mtime":1385717028000},"oswicdgo4kyzmw19":{"_id":"oswicdgo4kyzmw19","source":"themes\\light\\source\\fancybox\\fancybox_loading.gif","mtime":1385717028000},"w3k4m5yitkqg79wq":{"_id":"w3k4m5yitkqg79wq","source":"themes\\light\\source\\fancybox\\fancybox_loading@2x.gif","mtime":1385717028000},"l65r60lg0vvi8dt4":{"_id":"l65r60lg0vvi8dt4","source":"themes\\light\\source\\fancybox\\fancybox_overlay.png","mtime":1385717028000},"9rjmgxedqrbtkr6f":{"_id":"9rjmgxedqrbtkr6f","source":"themes\\light\\source\\fancybox\\fancybox_sprite.png","mtime":1385717028000},"gkxkcxsad984xkpa":{"_id":"gkxkcxsad984xkpa","source":"themes\\light\\source\\fancybox\\fancybox_sprite@2x.png","mtime":1385717028000},"2dzff041tnqt48ce":{"_id":"2dzff041tnqt48ce","source":"themes\\light\\source\\fancybox\\jquery.fancybox.css","mtime":1385717028000},"puk9pmig3q1s8epc":{"_id":"puk9pmig3q1s8epc","source":"themes\\light\\source\\fancybox\\jquery.fancybox.pack.js","mtime":1385717028000},"icl7cyop5bvr7tji":{"_id":"icl7cyop5bvr7tji","source":"themes\\light\\source\\js\\gallery.js","mtime":1385717028000},"pm7tqe4s9rs3eq58":{"_id":"pm7tqe4s9rs3eq58","source":"themes\\light\\source\\js\\jquery.imagesloaded.min.js","mtime":1385717028000},"cpl5iceweoopramd":{"_id":"cpl5iceweoopramd","source":"themes\\light\\source\\css\\style.styl","mtime":1385717028000},"j4v4tfnityz5a0oi":{"_id":"j4v4tfnityz5a0oi","source":"themes\\light\\source\\css\\font\\fontawesome-webfont.eot","mtime":1385717028000},"qaktejfhds6u7d2o":{"_id":"qaktejfhds6u7d2o","source":"themes\\light\\source\\css\\font\\fontawesome-webfont.svg","mtime":1385717028000},"94o6i2u7y8mbcxq4":{"_id":"94o6i2u7y8mbcxq4","source":"themes\\light\\source\\css\\font\\fontawesome-webfont.ttf","mtime":1385717028000},"m1scxdjcmu2wog95":{"_id":"m1scxdjcmu2wog95","source":"themes\\light\\source\\css\\font\\fontawesome-webfont.woff","mtime":1385717028000},"gf36iswkh2n81vkw":{"_id":"gf36iswkh2n81vkw","source":"themes\\light\\source\\css\\_partial\\header.styl","mtime":1385795847000},"p8uyerxu7x95f57i":{"_id":"p8uyerxu7x95f57i","source":"themes\\light\\source\\css\\_partial\\sidebar.styl","mtime":1385795745000},"ufc8r7l8sj0fa8my":{"_id":"ufc8r7l8sj0fa8my","source":"source\\img\\Havana架构.jpg","mtime":1382667864000},"z48x24qy1nvurcqh":{"_id":"z48x24qy1nvurcqh","source":"source\\img\\Havana-arch.jpg","mtime":1382667864000},"yqehwbu7lrjvwx5p":{"_id":"yqehwbu7lrjvwx5p","source":"source\\img\\Havana_arch.jpg","mtime":1382667864000},"kzgp9kpez8kpzlny":{"_id":"kzgp9kpez8kpzlny","source":"source\\img\\spine_leaf.png","mtime":1385901542000},"8nuau9norxg60av8":{"_id":"8nuau9norxg60av8","source":"source\\img\\l3switch1.jpg","mtime":1386055704000},"6hgiflaqzutac2xo":{"_id":"6hgiflaqzutac2xo","source":"source\\img\\l3switch2.jpg","mtime":1386055711000},"ttb51losid5hl32c":{"_id":"ttb51losid5hl32c","source":"source\\img\\l3switch3.jpg","mtime":1386055719000},"vbe2rv00zht7r9tq":{"_id":"vbe2rv00zht7r9tq","source":"source\\img\\bodi.JPG","mtime":1402632908000},"t76yaw315jyy8jon":{"_id":"t76yaw315jyy8jon","source":"source\\img\\Opera1.JPG","mtime":1402305098000},"gn1ifmxfuvfuoala":{"_id":"gn1ifmxfuvfuoala","source":"source\\img\\Opera2.JPG","mtime":1402625282000},"wpkkmfallejsevmz":{"_id":"wpkkmfallejsevmz","source":"source\\img\\SYDU.JPG","mtime":1414595340000},"7peqoewqh7csk6s6":{"_id":"7peqoewqh7csk6s6","source":"source\\img\\floodlight03-controller.png","mtime":1414675408000},"pxemxe20fkjmumm2":{"_id":"pxemxe20fkjmumm2","source":"source\\img\\wuzhen1.JPG","mtime":1409909172000},"rvim8uln96rjgeod":{"_id":"rvim8uln96rjgeod","source":"source\\img\\wuzhen2.JPG","mtime":1409913598000},"9bd11ifewbrgiy0n":{"_id":"9bd11ifewbrgiy0n","source":"source\\img\\wuzhen3.JPG","mtime":1409914562000},"b8a4e9pemfrrt1gt":{"_id":"b8a4e9pemfrrt1gt","source":"source\\img\\xihu.jpg","mtime":1414680335000},"0m6agvraqoh6j0qw":{"_id":"0m6agvraqoh6j0qw","source":"source\\img\\xihu2.JPG","mtime":1410093730000},"8axsgwh0vnlvx41d":{"_id":"8axsgwh0vnlvx41d","source":"source\\img\\Componentsofryu.png","mtime":1415455702000},"d1b1jr0cd63fc3rl":{"_id":"d1b1jr0cd63fc3rl","source":"source\\img\\ryudoc4dp.jpg","mtime":1416841252000},"bpttgl1duxpq2rc4":{"_id":"bpttgl1duxpq2rc4","source":"source\\img\\ryudoc4phase.jpg","mtime":1416840358000},"tjcbkhdso3icnm95":{"_id":"tjcbkhdso3icnm95","source":"source\\img\\python-inspect-result.jpg","mtime":1417017368000},"sjr8fejbg9lpowpf":{"_id":"sjr8fejbg9lpowpf","source":"source\\img\\ryu-source-analysis-4-features.jpg","mtime":1417698605000},"yogv122a2iybpp22":{"_id":"yogv122a2iybpp22","source":"source\\img\\ryu-source-flow-chart.jpg","mtime":1418483444000},"evdo6hn7pa5s4frt":{"source":"source\\img\\ryusourceflowchart.jpg","mtime":1418483444000,"_id":"evdo6hn7pa5s4frt"}},"Cache":{"iedf1ctlwftqwfe9":{"_id":"iedf1ctlwftqwfe9","content":"title: Hello World\ndate: 2013-11-29 17:23:48\ntags:\n---\n\nWelcome to [Hexo](http://zespia.tw/hexo)! This is your very first post. Check [documentation](http://zespia.tw/hexo/docs) to learn how to use.","mtime":1385717028000,"source":"_posts/hello-world.md"},"rvyipwfxc8am0q83":{"_id":"rvyipwfxc8am0q83","content":"title: test\ndate: 2013-11-29 22:52:28\ntags:\n---","mtime":1385736748000,"source":"_posts/test.md"},"t2ws2scuyd3n7bu6":{"_id":"t2ws2scuyd3n7bu6","content":"title: new\ndate: 2013-11-29 23:15:02\ntags:\n---","mtime":1385738102000,"source":"_posts/new.md"},"176gn1qnbbcxk8qe":{"_id":"176gn1qnbbcxk8qe","content":"title: ChinaNet骨干网拓扑结构\ndate: 2013-11-29 23:15:02\ntags: Network\ncategories: Network\n---\n\nChinanet 骨干网的拓扑结构逻辑上分为两层，即核心层和大区层。\n\n1.1 核心层\n\n核心层由北京、上海、广州、沈阳、南京、武汉、成都、西安等8个城市的核心节点组成。\n\n<!--more-->\n核心层的功能主要是提供与国际internet的互联，以及提供大区之间信息交换的通路。其中北京、上海、广州核心层节点各设有两台国际出口路由器，负责与国际i nternet互联，以及两台核心路由器与其他核心节点互联；其他核心节点各设一台核心路由器。\n\n核心节点之间为不完全网状结构。以北京、上海、广州为中心的三中心结构，其他核心节点分别以至少两条高速ATM链路与这三个中心相连。\n\n1.2 大区层\n\n全国31个省会城市按照行政区划，以上述8个核心节点为中心划分为8个大区网络，这8个大区网共同构成了大区层。每个大区设两个大区出口，大区内其它非出口节点分别与两个出口相连。\n\n大区层主要提供大区内的信息交换以及接入网接入chinanet的信息通路。\n大区之间通信必须经过核心层。\n\n2. 路由协议\n\n当前路由政策国际部分采用BGP4与国外其它网络进行路由交换，国内部分采用BGP4进行与省网内进行地址交换，而采用IS-IS进行骨干网内部的路由选择。\n\n2.1 BGP\n\nBGP是域间路由协议。Chinanet骨干网申请的自治域号为4134，Chinanet作为一个独立的自治域，采用BGP路由协议与国际 internet及各省接入网交换路由信息。骨干网内路由器之间是I BGP，骨干网和国外及接入网之间是EBGP。但是IBGP路由在自治域内只会向前传递一次，所以IBGP路由器之间需要具有全网状连接（full mesh），才能保证每台路由器都收到完整的路由，但是骨干网内路由器数量很多，做全网状连接是不现实的，因此骨干网采用BGP Confedration 的方法；对内将骨干网用私有AS号划分为9个私有AS域，每一个小的自治域中，IBGP采用全网状的联接方式，自治域之间为EBGP联接方式。对外通过BGP Confedration将这些AS集合成一个独立的AS 4134。这样，ChinaNET骨干网就采用AS 4134分别与国际Internet以及各省网交换路由信息，在内部用私有AS号交换路由。\n\n2.2 ISIS\n\nISIS是一种IGP(内部网关协议)，通过ISIS路由协议可以对从BGP学来的nexthop进行寻径。\n\n在ChinaNET骨干网中使用single IGP。即核心层及八个大区层网络中使用同一个Tag(core)的IS-IS。采用Single IGP的好处是所有的IS-IS路由器可以正常地交换IS-IS路由信息。如果采用不同的Tag，则不同tag下的isis彼此交换路由，需要 redistrib ute，这将导致许多不必要的麻烦。\n\n2.1.1 AREA的划分\n\nISIS路由协议是一种link state路由协议，它的一个特点就是在一个域内可以分为很多个区，如果一台路由器的路由表发生变化，它就会向本区内的其他路由器广播这一变化，直到同一区内的所有路由器都将形成一张完全相同的本区的拓扑图为止。由于ChinaNET骨干网路由器及链路数量很多，如果所有路由器都在一个区的话，每一条路由的变化，都会导致全网的路由器进行路由更新，这将大大降低网络的效率。因此根据骨干网的网络结构状况，将chinanet划分为九个IS-IS域，核心层网络与八个大区层网络分别处于一个独立的区域内。这样就将链路状态的频繁变化对网络的影响限制于一个区域内部，而不致于对全网产生影响。\n\n2.1.2 Level-1和Level-2路由\n\n在ISIS中，路由可分为两类：level-1和level-2。level-1的链路信息可以从level-2的链路上广播，而level-2的链路信息不可以从level -1的链路上广播。level-1的路由和level-2的路由在路由器内分别在两个数据库中。如果某台路由器只有level-1路由的数据库，则称为l evel-1 router ，反之为level-2路由器。level-1 router只和与它具有相同area id的路由器交换路由信息，而level-2路由器可以和与它具有相同area id的路由器交换路由信息。如果level-1 router发现IP包的目的地址与它的area id 不同，它就会将此包自动转发到离它最近的(并不一定最好)的level-2路由器上。区分level-1和level-2路由可以减少路由交换的数量，提高网络的效率。\n\n2.1.3 ISIS metric\n\nISIS 的路由选择通过metric实现，metric值越小越优先。Metric的范围为0～63，缺省为10。目前Chinanet骨干网根据主要根据链路带宽的大小设置m etric的优先级，带宽越大，metric值越小，这样网络可以动态地优先选择大带宽的路径。\n\n2.1.4 静态路由和直连路由的广播\n\n路由器上设置的静态路由，为了使它加入到ISIS的路由表中去，需要将静态路由redistribute进ISIS中。同样，在isis core 的边缘上路由器，如国际出口链路和大区与接入之间链路，也需要redistribute进ISIS。\nRedistribute的原则是：国际和核心路由器redistribute进level-2，大区出口路由器redistribute进level-1和level-2，大区内路由器r edistribute进level-1。 ","mtime":1385781026000,"source":"_posts/ChinanetTopo.md"},"1vlu1nl20hxqql53":{"_id":"1vlu1nl20hxqql53","content":"---\nlayout: about\ntitle: \"About\"\n---\n## Wei Wang ##\n\nPhD Cadidate in Computer Networks\n\nICT, Kexueyuan South Road, Haidian, Beijing, RPC\n\n**Short Biography**\n\n- 2012~Now  Ph.D, ICT & UCAS\n- 2008~2012 BE, School of Software, DLUT\n\n**Research Interest**\n\t\n- Content Centric Network: routing, caching, naming\n- DataCenter Network: flow schedule, rate control, measurement, load balance \n- Software Defined Network & Network Virtualization: general architecture, openflow, controller, application, vswitch, NFV\n \n**Interested Open Source Projects**\n\n- [Openvswitch](http://openvswitch.org/)\n- [OpenStack](http://www.openstack.org/)\n- [Floodlight](http://www.projectfloodlight.org/floodlight/)\n- [NDNSim](http://ndnsim.net/)\n\n**Publications**\n\n**Freeway: Adaptively Isolating the Elephant and Mice Flows on Different Transmission Paths**\n\n**Wei Wang**,Yi Sun, Kai Zheng, Mohamed Ali Kaafar, Dan Li, Zhongcheng Li, IEEE ICNP 2014\n\n\n**CRCache: Exploiting the correlation between content popularity and network topology information for ICN caching**\n\n**Wei Wang**, Yi Sun,Yang Guo, Kaafar, D., Jiong Jin, Jun Li, Zhongcheng Li, IEEE ICC 2014\n\n**A Balanced Energy Consumption Solution for Wireless Sensor Networks with Failure Clusters**\n\n**Wei Wang**, Tie Qiu, Lei Wang, Feng Xia, Guowei Wu, IEEE CSAE 2011\n\n**Queueing-network-based Delay Analysis and Path Selection Improvement of Wireless Sensor Network**\n\nLin Feng, **Wei Wang**, Tie Qiu, Weifeng Sun, Yu Zhou, Sensor Letters, Volume 11, Number 4, April 2013\n\n**A Failure Self-recovery Strategy with Balanced Energy Consumption for Wireless Ad Hoc Networks**\n\nTie Qiu, **Wei Wang**, Feng Xia, Guowei Wu, Yu Zhou, Journal of Computers, Volume 7, No. 1, 2012\n\n\n2014/10/29 23:38:40 Updated","mtime":1414597238000,"source":"about/index.md"},"ecozcqrs9vqrd3no":{"_id":"ecozcqrs9vqrd3no","content":"title: Github搭建Hexo\ndate: 2013-11-30 16:08:28\ntags: \n- Hexo\n- github\ncategories: Others\n---\n\n\n\n搞了一天终于搞定了Hexo的搭建，今后把博客开在这里了，来记录我工作学习和生活。\n\n<!--more-->\n\n之前就一直想写博客，记录我的学习历程，最开始搭建在GAE上，后来总是要翻墙，比较麻烦，就停止了。再后来转战Evernote了，记录在本地了，后来发现这样无法与广大学者交流学习，提高比较慢，分享的也少，所以就又筹划着开博客了。\n\n然后就，我的前提是不买VPS，不买域名，反正就是不花钱（本人是穷PhD一枚），Google了一下，发现Githug Pages还不错，它的初衷是给github上的项目提供一个介绍页的，避免大家直接看到烦乱的Code。但是也可以作为一个host，搭建我们的Blog（程序员们太聪明了）。而且可以用git的方式更新，太方便了。\n\nHost有了，用什么搭建呢？Google下发现，Hexo利用node.js，而且和github结合的比较紧密，搭建方便。\n\n我是在windows上搭建的，估计大多数朋友写博客也是在window吧,，闲话少说，切入正题.\n\n**准备工作**\n\n首先需要一个github的账号\n\n下载安装git，下载地址 [http://msysgit.github.io/](http://msysgit.github.io/)\n安装git的时候最好选上那个在CMD中也可以运行的选项，否则以后更新博客的时候必须得用那个git bash\n\n下载安装node.js，下载地址 [http://nodejs.org/](http://nodejs.org/)\n\n安装hexo\n\n在命令行中输入\n\n    npm install -g hexo\n    hexo init <your folder> #博客在本地将来要放的地方\n\n然后就在指定的目录中生成了一堆的文件，此时在本地已经有了基本的blog的框架了。\n\n**使用与配置**\n\n可以在本地预览一下默认的blog的样子，在你指定的目录中（必须是在那个目录下）输入：\n\n    hexo server\n\n启动本地服务器，然后在浏览器打开 [localhost:4000](localhost:4000)，就可以预览了\n\n接下来就要将你的本地blog部署到Github上，但在这之前需要做一个重要的工作，就是使用ssh-key可以登录github，没有这个的话后面会遇到很多access deny的麻烦，方法很简单\n\nssh-keygen -t rsa\n\n连续按三次回车就会生成，~/.ssh/id_rsa.pub，用记事本打开，将其复制到github->accounting setting->SSH Key->Add SSH Key 的Key一栏中，名称自己随便取。之后会让你填一下github的密码。\n\n然后在cmd中输入\n\n    ssh -vT git@github.com\n\n来测试是否成功\n\n成功后，修改*_config.yml* 文件的deploy项，注意type前面的缩进和冒号后面的空格\n\n\tdeploy:\n  \t\ttype: github\n  \t\trepository: git@github.com:weiwang1206/weiwang1206.github.io.git\n  \t\tbranch: master\n\n这里需要注意的是，首先得有一个project在github中，而且名字**必须**为 *username*.github.io\n\n生成并部署\n\n\thexo deploy --generate\n\n\n之后我们就可以在浏览器打开 *username*.github.io 来访问网页，可能需要等一会儿。\n\n然后具体hexo如何写blog可以参加hexo的[官方网站](http://zespia.tw/hexo/)来学习","mtime":1385802571000,"source":"_posts/Hexo-Build.md"},"333c1u3hlcdd4l2p":{"_id":"333c1u3hlcdd4l2p","content":"title: Openstack开篇\ndate: 2013-11-30 16:22:54\ntags: \n- OpenStack\n- Network\ncategories: OpenStack\n---\n\n实验室一直在在CENI项目，我们课题组打杂帮忙做一个vrouter网管系统，本来以为打打酱油，但后来发现了OpenStack，和我们项目差不多，只不过OpenStack管理vm我们管理vrouter。因此来学习下OpenStack的管理方式。\n\n<!--more-->\n\n之前就开始关注OpenStack，是因为国内有个QingCloud的初创公司饱受好评，貌似在IaaS领域国内首屈一指。但好像他们的Project不是基于Openstack的，反正他们的CEO是这么说的。也有好多初创公司基于OpenStack做公有云，比如[UnitedStack](http://www.ustack.com/)。\n\n之前也积累了一些资料，下面贴上一张Openstack Havana的架构图。\n\n![havana](/img/Havana_arch.jpg)\n\n\n因为专业是Networking，所以今后先从网络组件Neutron开始。","mtime":1385802697000,"source":"_posts/openstack-overview.md"},"xwbu42gl3lnqjeb5":{"_id":"xwbu42gl3lnqjeb5","content":"title: openstack-overview\ndate: 2013-11-30 16:35:55\ntags:\ncategories:\n---","mtime":1385800555000,"source":"_posts/openstack-overview-1.md"},"jwg1njm7g4m5qq45":{"_id":"jwg1njm7g4m5qq45","content":"title: 数据中心网络Flow Schedule\ndate: 2013-12-01 20:14:10\ntags: \n- Network\n- DataCenter Network\n- Flow Schedule\ncategories: Research\n---\n\n\n当今各大互联网公司的访问量呈爆炸式增长，巨大的访问量对其DataCenter造成巨大的压力，尤其是数据中心内部网络。数据中心现有的业务很多也是Deadline-aware的，比如Web search，social network，recommendation system等，每多1ms的延迟，就会造成很大的损失，这不是危言损听。而且这些业务也都有SLA（Service Level Agreement）的要求，大概数字在300ms左右[D2TCP]。因此，保证DC内部网络的软实时性很重要。\n\n<!--more-->\n\n**Datacenter Network 背景及Traffic特征**\n\n（比较零碎，等形成完整的思路再整合）\n\n\n- 内部拓扑基本上就是Spine-Leaf，一个机架上的所有主机连接在一个ToR（Top of Rack）上，这些交换机连接在每个core switch上，这样做的好处是不让上层的switch成为bottleneck，并且提供了multipath\n\n![spine_leaf](/img/spine_leaf.png)\n\n\n\n\n- 现在的数据中心99%的traffic跑着TCP连接[DCTCP]\n\n\n- traffic中绝大多数是deadline aware short flow；也有少数的elephant long flow，但没有严格的deadline，占据着较大的带宽；两种类型的flow混合着争夺着现有的带宽资源。\n\n\n- 带宽情况，edge switch出口1G最多10G，core switch 10G。\n\n\n- switch的buffer很小，大概在百K左右，上M的少，不过Cisco有16M的，但是总体来说不大。尤其是数据中心里都是普通commodity switch。而且这个仅有的buffer也是各端口共享的。buffer用来干嘛？queue！\n\n\n- traffic pattern主要是partition-aggregation，比如web search和hadoop。这就带来了incast问题。\n\n\n**传统TCP为什么不能胜任**\n\n这个主要还是没有很好的解决incast的问题，引起这个的原因是如果一个switch同时接受了很多flow，超过buffer之后肯定是要丢包的，丢包会引起TCP重传，但是重传是由RTO控制的，RTO长了延时过长，RTO短了既浪费带宽又导致队列长度过长也增加了延时。\n\n而且基本上对网络资源的利用也是fair sharing，在switch里基本就是FCFS。\n\n**Related Work**\n\n在学术界，近几年对这个问题比较关注，都在flow schedule方面发文章，从sigcom09到sigcomm13都有相关的文章。\n\n不过大约分为两类\n\n一类是不关注路径，single path，但是关注congestion contrll，rate controll，及交换机根据优先级进行处理\n\n一类是类似Load Balance的，专注multipath。\n\n**第一类代表文章**\n\n----------\n\nDCTCP （2010） --> D3 （2011） --> D2TCP & PDQ & Detail （2012） --> pFabric & OVN （2013）\n\n\n----------\n\n分别对每篇文章的方法，优势和劣势做下简单总结（等慢慢丰富）：\n\n**DCTCP**\n\n方法：使用优化的ECN，就是使用连续几个EC bit来计算网络拥塞程度，来调节TCP的window size从而控制拥塞，switch保持较低的值。\n\n优势：充分分析了DCN traffic，较早提出这个方法\n\n劣势：fair shareing，不关注deadline，无法保证SLA\n\n----------\n\n**D3**\n\n方法：使用贪心的方法，根据deadline和remaining flow size来确定一个rate，然后由switch为每个flow预留带宽。\n\n优势：提出使用deadline aware的方法保证按时交付和FCT\n\n缺陷：使用贪心的方法，导致先来的flow可能阻碍稍微后来一点的更重要的flow的延迟。先来先服务。\n\n----------\n\n\n**PDQ**\n\n方法：提出抢占式，后来的高优先级的可以是之前的flow先pause，就是针对D3的问题解决的。\n\n优势：抢占式很好，但是还有有些小问题，比如flow平滑过度，utilization等问题\n\n劣势：没看出来，在pFabric里说不好实现之类的\n\n----------\n\n**第二类代表文章**\n\n**Hedera**\n\nHedera关注的是数据中心内部不同机架之间的流量调度问题，和DCTCP，D3等关注的问题不太一样。Hedera认为inter-rack存在网络瓶颈。而且解决思路也不同，举个例子来说，第一类方法是红绿灯，在拥堵的路口指挥那辆车先走并且控制来这里的车辆的速率，Hedera是线路规划局，直接指挥车辆走别的路。\n\n方法：充分利用数据中心equal cost的特性，预估流的带宽需求，设计优化的flow schedule算法，将流调度到带宽压力较小的switch上。这种需要全局信息来做调度，可以充分利用SDN的思想，做全局优化。\n\n优势：比ECMP静态的路径要有优势，可以充分利用多条路径，避开繁忙的链路\n\n缺陷：流在过程中会改变路径，调度算法太简单，没有抢占，没有优先级，在共享内存的交换机中，简单的流调度可能不好，因为elephant background flow可能占据了大量的内存，这样的flow应该为deadline aware的流做出让步。Flow的带宽预测有些weight，其实根据deadline和flow size就可以确定一个流的重要性了。Schedule的运行频率也是一个影响performance的因素，频率太小，效果不明显，频率高造成浪费资源。\n\n基于Hedera这里可以写一个Flow schedule算法\n\n**Per-packet Load-balanced low latency routing for clos-based data center Networks**\n\n这篇文章的核心思想是为Clos based network（比如Fat tree，VL2）提供packet level的load balanced算法，这个算法DRB在server端选择一个core switch作为其中转的destination（IP in IP，在core switch 解包发到真正的destination），并且根据拓扑的特性，确定唯一的路径，使用静态路由\n\n缺点：re-odering，switch解包，需要server知道拓扑状态尤其是所有的core switch（其实这一步感觉在网络中做更好，host端做好rate control就好了），静态路由扩展性较差\n\n（未完待续）","mtime":1386597356000,"source":"_posts/flow-schedule-1.md"},"4996fkxyp7dkw69h":{"_id":"4996fkxyp7dkw69h","content":"title: 深度分析三层交换机（转）\ndate: 2013-12-03 15:23:57\ntags:\n- Network\n- Switch\ncategories: Network\n---\n\n\n\n看到一篇深度分析3层交换机的文章写的不错，转载在这里，[原文地址](http://blog.csdn.net/shmily_cml0603/article/details/9411211)\n\n<!--more-->\n\n路由器的三层转发主要依靠CPU进行，而三层交换机的三层转发依靠ASIC芯片完成，这就决定了两者在转发性能上的巨大差别。当然，三层交换机并不能完全替代路由器，路由器所具备的丰富的接口类型、良好的流量服务等级控制、强大的路有能力等仍然是三层交换机的薄弱环节。目前的三层交换机一般是通过VLAN来划分二层网络并实现二层交换的，同时能够实现不同VLAN间的三层IP互访。在讨论三层交换机的转发原理之前有必要交代一下不同网络的主机之间互访时的行为：\n\n（1）源主机在发起通信之前，将主机的IP与目的主机的IP进行比较，如果两者位于同一个网段（用网络掩码计算后具有相同的网络号），那么源主机直接向目的主机发送ARP请求，在收到目的主机的ARP应答后获得对方的物理层（MAC）地址，然后用对方MAC作为报文的目的MAC进行报文发送。位于同一VLAN（网段）中的主机互访时属于这种情况，这时用于互连的交换机作二层交换转发；\n\n（2）档源主机判断目的主机与主机位于不同的网段时，它会通过网关（Gateway）来递交报文，即发送ARP请求来获取网关IP地址对应的MAC，在得到网关的ARP应答后，用网关MAC作为报文的目的MAC进行报文发送。注意，发送报文的源IP是源主机的IP，目的IP仍然是目的主机的IP。位于不同VLAN（网段）中的主机互访时属于这种情况，这时用于互连的交换机作三层交换转发。\n为了后续讨论的三层交换原理便于理解，这里简单介绍一下三层交换机内部结构，如图1所示：\n\n![图1 三层交换机硬件结构](/img/l3switch1.jpg)\n\n三层交换机内部的两大部分是ASID和CPU，它们的作用分别如下：\n\n1.ASIC：完成主要的二三层转发功能，内部包含用于二层转发的MAC地址表以及用于IP转发的三层转发表；\n\n2.CPU：用于转发的控制，主要维护一些软件表项（包括软件路由表、软件ARP表等等），并根据软件表项的转发信息来配置ASIC的硬件三层转发表。当然，CPU本身也可以完成软件三层转发。\n\n从三层交换机的结构和各部分作用可以看出，真正决定高速交换转发的是ASIC中的二三层硬件表项，而ASIC的硬件表项来源于CPU维护的软件表项。\n\n下面分别以两种组网情况下主机间的通信来解释三层交换机的转发原理。\n组网１如图2所示，通信的源、目的主机连接在同一台三层交换机上，但它们位于不同VLAN（网段）。对于三层交换机来说，这两台主机都位于它的直连网段内，它们的IP对应的路由都是直连路由。\n\n![图2 三层转发组网1](/img/l3switch2.jpg)\n\n图2中标明了两台主机的MAC、IP地址、网关，以及三层交换机的MAC、不同VLAN配置的三层接口IP。当PC A 向PC B 发起ICMP请求时，流程如下：（假设三层交换机上还未建立任何硬件转发表项）\n\n1.PC A首先检查出目的IP地址2.1.1.2（PC B）与自己不在同一个网段，因此它发出请求网关地址1.1.1.1对应MAC的ARP请求；\n\n2.L3_SW收到PC A 的ARP请求后，检查请求报文，发现被请求IP是自己的三层接口IP，因此发送ARP应答并将自己的三层接口MAC(MAC S)包含在其中。同时它还会把PC A 的IP 地址与MAC地址对应起来（1.1.1.2<==>MAC A）关系记录到自己的ARP表项中去（因为ARP请求报文中包含了发送者的IP和MAC）；\n\n3.PC A得到网关（L3_SW）的ARP应答后，组装ICMP请求报文并发送，报文的目的MAC = MAC S 、源MAC = MAC A 、源IP＝1.1.1.2、目的IP = 2.1.1.2；\n\n4.L3_SW收到报文后，首先根据报文的源MAC+VID（即VLAN ID）更新MAC地址表。然后，根据报文的目的MAC+VID查找MAC地址表，发现匹配了自己三层接口MAC的表项。这里说明一下，三层交换机为VLAN配置三层接口IP后，会在交换芯片的MAC地址表中添加三层接口MAC+VID的表项，并且为表项的三层转发标志置位。当报文的目的MAC匹配这样的表项以后，说明需要作三层转发，于是继续查找交换芯片的三层表项；\n\n5.芯片根据报文的目的IP去查找其三层表项，由于之前未建立任何表项，因此查找失败，于是将报文送到CPU去进行软件处理；\n\n6.CPU根据报文的目的IP去查找其软件路由表，发现匹配了一个直连网段（PC B对应的网段），于是继续查找其软件ARP表，仍然查找失败。然后L3_SW会在目的网段对应的VLAN3的所有端口发送请求地址2.1.1.2对应MAC的ARP请求；\n\n7.PC B收到L3_SW发送的ARP请求后，检查发现被请求IP是自己的IP，因此发送ARP应答并将自己的MAC（MAC B）包含在其中。同时，将L3_SW的IP与MAC的对应关系（2.1.1.1＜＝＝＞MAC S）记录到自己的ARP表中去；\n\n8.L3_SW收到PC B的ARP应答后，将其IP和MAC对应关系（2.1.1.2<==>MAC B）记录到自己的ARP表中去，并将PC A的ICMP请求报文发送给PC B，报文的目的MAC修改为PC B 的MAC（MAC B），源MAC修改为自己的MAC（MAC S）。同时，在交换芯片的三层表项中根据刚才得到的三层转发信息添加表项（内容包括IP、MAC、出口VLAN、出端口等），这样后续的PC A发送PC B的报文就可以通过该硬件三层表项直接转发了；\n\n9.PC B收到L3_SW转发过来的ICMP请求报文以后，回应ICMP应答给PC A。ICMP应答报文的转发过程与前面类似，只是由于L3_SW在之前已经得到PC A的IP和MAC对应关系了，也同时在交换芯片中添加了相关的三层表项，因此这个报文直接由交换芯片硬件转发给PC A；\n\n这样，后续的往返报文都经过查MAC表＝＞查三层转发表的过程由交换芯片直接进行硬件转发了。\n从上述流程可以看书，三层交换正是充分利用了“一次路由（首包CPU转发并建立三层转发硬件表项）、多次交换（后续包芯片硬件转发）”的原理实现了转发性能与三层交换的完美统一。\n \n下面介绍另一种组网情况的三层转发流程，如图３所示。\n\n![图3 三层转发组网1](/img/l3switch3.jpg)\n\n图３中标明了两台主机的MAC、IP地址、网关，以及两台三层交换机的MAC、不同VLAN配置的三层接口IP。假设L3_SW１上配置了静态路由：IP route 2.1.1.0　255.255.255.0　3.1.1.2；L3_SW2上配置了静态路由：IP route 1.1.1.0　255.255.255.0　3.1.1.1。当然，路由信息也可以通过动态路由协议的交互来获得，有关路由的知识请查阅相关文档。\n这种组网情况下的转发过程与图２的组网１情况是类似的，下面的流程讲解中降省略部分前面已经分析过的细节问题。当PC A向PC B发起ICMP请求时，流程如下：（假设三层交换机上还未建立任何硬件转发表项）\n1.PC A首先检查出目的IP地址2.1.1.2（PC B）与自己不在同一个网段，因此它通过ARP解析得到网关地址1.1.1.1对应的MAC（MAC　S1）。然后，PC A组装ICMP请求报文并发送，报文的目的MAC=MAC S1、源MAC=MAC　A、源IP=1.1.1.2、目的IP=2.1.1.2；\n\n2.L3_SW1收到报文后，首先根据报文的源MAC+VID更新MAC地址表。然后，根据报文的目的MAC+VID查找MAC地址表，发现匹配了自己三层接口MAC的表项，于是继续查找芯片的三层转发表；\n\n3.由于之前未建立任何表项，因此三层转发表查找失败，于是将报文送到CPU去进行软件处理；\n\n4.CPU根据报文的目的IP去查找其路由软件表，发现匹配路由2.1.1.0/24，其下一跳IP地址为3.1.1.2，于是继续查找3.1.1.2是否有对应的ARP，仍然查找失败。然后L3_SW1在下一跳地址3.1.1.2对应的VLAN4内发起ARP请求，并得到L3_SW2的回应，从而得到Ｉ和MAC对应关系（3.1.1.2＜＝＝＞MAC S2）；\n\n5.L3_SW1将PC A发出的ICMP请求报文转发给L3_Sw2，报文的目的MAC修改为L3_SW2的MAC（MAC　S2），源MAC修改为自己的MAC（MAC　S1）。同时，将刚刚用到的转发信息添加到交换芯片的三成转发表中去，包括匹配的网段2.1.1.0/2４、下一跳地址的MAC（MAC　S2）、出口VLAN、出端口。这样，后续发往2.1.1.2的报文就可以直接通过交换芯片硬件转发了；\n\n6.L3_SW2收到报文后，与组网１中的处理类似，经过查MAC表＝＞查三层转发表＝＞送CPU＝＞匹配直连路由＝＞ARP解析＝＞转发报文同时添加硬件表项的过程，将报文转发给PC B，此时报文的目的MAC修改为PC B的MAC（MAC　B），源MAC修改为L2_SW2的MAC（MAC　S2）。这样后续发往2.1.1.2的报文就直接由交换芯片硬件转发了；\n\n7.PC B收到来自PC A的ICMP请求报文后进行ICMP应答。由于在ICMP请求报文转发的过程中，每个网段的两端节点都已经通过ARP解析得到了对方的IP和MAC对应关系，因此应答报文的转发完全由交换芯片完成（查MAC表＝＞查三层转发表＝＞发送）；\n\n这样，后续的往返报文都经过查MAC表＝＞查三层转发表的过程由交换芯片直接进行硬件转发了。\n\n从上述两种组网情况下的转发流程可以看出，三层交换机的转发具有以下特点：\n\n1.首包通过CPU转发，同时建立交换芯片硬件表项；后续包由交换芯片直接硬件转发，即常说的“一次路由、多次交换”；\n\n2.交换芯片的硬件转发并不关心路由的具体下一跳IP地址是多少，硬件三层表项中只包含了目的地址（或网段）、目的IP（或下一跳IP）对应的MAC、出口VLAN、出端口；（这里说明一下，并不是所有的三层交换机的硬件三层表项都会包含“出端口”的。）\n\n3.IP报文每经过一次三层转发，它的源、目的MAC都会变化，但是源IP、目的IP是始终不变。\n \n在三层交换转发中，交换芯片（ASIC）起到了至关重要的作用，因此三层交换机的性能和转发特点主要取决于交换芯片的实现机制。在三层交换原理一节中讲解的三层交换原理只是一个大致的转发流程，对于使用了不同交换芯片的三层交换机，其硬件转发过程中的一些细节内容是有所区别的。本节主要就硬件三层表项的结构和查表方式介绍几种不同的实现。\n \n从前面的描述可以看出，三层转发是必然需要路由信息的，而转发过程中的路由选择决定了报文的最终出口如何，三层交换机只是将这种路由功能整合到交换芯片中去了。路由选择存在精确匹配和最长匹配两种方式，精确匹配即目的ＩＰ地址与路由的地址信息必须完全吻合，而最长匹配则是选择所有包含了目的地址的路由中掩码最长的一条。\n\n早期的三层交换机上，其交换芯片多采用精确匹配的方式，它们的硬件三层表项中只包含其目的ＩＰ地址，并不带掩码信息。比如在转发目的IP为2.1.1.2的报文时，通过软件查找匹配了非直路由2.1.1.0/24，那么就将2.1.1.2的转发信息添加到交换芯片中去，如果继续来了目的IP为2.1.1.3的报文需要转发，则需要重新进行软件查找，并在交换芯片中为2.1.1.3增加新的表项。这样的选录方式表项结构对交换芯片的硬件资源要求很高，因为芯片中集成的表项存储空间是有限的，如果要发大量目的IP地址不同的报文那么就需要添加大量的硬件表项。曾经泛滥一时的冲击波病毒，就导致了当时大量的只支持精确匹配的三层交换机资源耗尽。因为冲击波病毒的手段之一就是发送巨数量的网段扫描报文，而多数三层交换机上都配置了缺省路由，这样所有的报文在CPU软件查找都能够找到匹配路由，进而针对每一个病毒报文的目的IP都需要新增硬件表项并迅速将硬件资源满。这样，大部分用户的正常数据流由于转发资源耗尽而得不到高速处理了。\n\n由于精确匹配方式的三层交换机的这种缺陷，后期的三层交换机增加了对最长匹配方式的支持，即硬件三层表项中可同时包含IP地址和掩码，在查找时遵循最长匹配原则。这种类型的三层交换机，一般在软件路由表建立时就将路由信息添加到硬件三层表中去，包括直连路由和非直连路由。对于直连路由，对应的硬件三层表项的“TO　CPU”标志位始终置１，报文的目的IP匹配这样的表项被送往CPU处理，CPU软件会在直连网段发送ARP请求，并将获取的ARP信息作为主机路由添加到硬件表项中（对应的“TO　CPU”标志位置0），这样后续的同样目的IP的报文就直接通过新添加的硬件表项转发了；对于非直连路由，当下一跳地址对应ARP信息还未获得时，对应的硬件三层表项的“TO　CPU”标志位置１，报文的目的ＩＰ匹配这样的表项以后被送往CPU处理，CPU软件会在下一跳地址对应的直连网段发送ARP请求，并使用获取的ARP信息中的下一跳MAC、出口VLAN等信息更新对应的硬件三层表项，然后将其“TO CPU”标志位置0，这样后续的目的IP匹配该非直连路由的报文就能够直接通过修改后的硬件表项转发了。\n\n目前，大多数的三层交换机均能够同时支持精确匹配表项和最长匹配表项，一般来说精确匹配表项对应于软件中的ARP表，最长匹配表项对应于软件中的直连路由和非直连路由。\n\n在交换机三层转发流程中，曾经提到，硬件三层表项由目的IP（或网段）、目的IP（或下一跳IP）对应MAC、出口VLAN、出端口组成，采用这样表项的三层交换芯片一般直接通过查找三层转发表项就能够完成转发。这种处理机制流程简单、转发效率高，但是也使得CPU软件对硬件表项的配置控制比较复杂，因为每当ＩＰ地址对应的ＭＡＣ和物理端口出现变化，就必须对三层转发表项进行更新。而在交换机上二层信息变化的可能性是比较大的，特别是交换机支持链路聚合、生成树等冗余机制，所以在某些应用环境中CPU不得不经常的对三层转发表进行更新，一旦更新出现问题（特别是出端口错误）必然对转发造成严重的不利影响。\n\n不过，并不是所有的三层交换机的硬件三层表项都带有出端口信息，部分交换芯片使用的硬件表项只包括目的IP（或网段）、目的IP（或下一跳IP）对应的MAC、出口VLAN，从转发流程上来说有以下变化：根据报文的目的IP查找三层转发表后，只得到了目的IP或下一跳IP）对应的MAC和出口VLAN；然后继续根据MAC＋VID去查找MAC地址表，并最终获得出端口信息，如果查找MAC表失败的话会在出口VLAN进行广播。这样的处理机制虽然增加了芯片处理复杂度，但是流程更加清晰合理，CPU的处理更加简单，因为物理出口的变化只需要反映在MAC地址表中就可以了，硬件三层表项无需频繁更新。\n这两种处理方式的交换芯片各有优势，不同厂商会根据成本、可靠性、产品定位等各方面因素来进行选择，这也使得不同型号的三层交换机在同一应用环境中可能有不同的表现。","mtime":1386058233000,"source":"_posts/l3_switch.md"},"j8uenm89suhtg501":{"_id":"j8uenm89suhtg501","content":"title: Floodlight No.1\ndate: \ntags: \n- Floodlight\n- Controller\ncategories: Floodlight\n---\n\n\nFloodlight 学习笔记--No.1\n\nFloodlight采用模块化的方法加载各种服务。\n\n在各个模块中，FloodlightProvider模块，起到统领的作用，提供IFloodlightProviderService服务，具体来说就是提供controller服务。\n\n在main函数中，在加载完毕各种模块之后，获取FloodlightProviderService对象，即controller对象，执行其run函数。\n\n本系列博客文章针对版本号为0.90的Floodlight源码进行分析，旨在学习基本的SDN控制器的结构组成，运行原理，并与读者分享与讨论。鉴于能力有限，欢迎指出错误并指正。","mtime":1414679043000,"source":"_posts/Floodlight01.md"},"uel9usg2chf80pfc":{"_id":"uel9usg2chf80pfc","content":"title: Sydney\ndate: \ntags: \n- Photo\ncategories: Photo\n---\n\n在悉尼参加会议时拍的照片\n![歌剧院](/img/Opera1.JPG)\n\n<!--more-->\n\n![歌剧院](/img/Opera2.JPG)\n![邦迪海滩](/img/bodi.JPG)\n![悉尼大学](/img/SYDU.JPG)\n","mtime":1414595484000,"source":"_posts/SYD1.md"},"cqpe15vf6r83mhl8":{"_id":"cqpe15vf6r83mhl8","content":"title: Floodlight No.2\ndate: 2014/10/30 21:16:47 \ntags: \n- Floodlight\n- Controller\ncategories: Floodlight\n---\n\n## 代码结构 ##\n\nFloodlight代码总体上分为两部分：floodlight controller和openflow协议。floodlightcontroller部分包含了控制器的核心部件(core)，各个服务模块(module)以及相关工具组件。Openflow部分主要定义了openflow协议标准。Floodlight由各个模块组成，每个模块又可以提供不同的服务。\n\n\n## 控制器核心组件（core） ##\nFloodlight通过模块的方式来提供控制器的扩展性，core组件负责组件核心框架，包括网络通信，模块接口等，是其他模块的基础。首先，从main函数开始。\n<!--more-->\n## Main函数 ##\n\n    public static void main(String[] args) throws FloodlightModuleException {\n        // Setup logger\n        System.setProperty(\"org.restlet.engine.loggerFacadeClass\", \n                \"org.restlet.ext.slf4j.Slf4jLoggerFacade\");\n        \n        CmdLineSettings settings = new CmdLineSettings();\n        CmdLineParser parser = new CmdLineParser(settings);\n        try {\n            parser.parseArgument(args);\n        } catch (CmdLineException e) {\n            parser.printUsage(System.out);\n            System.exit(1);\n        }\n        \n        // Load modules\n        FloodlightModuleLoader fml = new FloodlightModuleLoader();\n        IFloodlightModuleContext moduleContext = fml.loadModulesFromConfig(settings.getModuleFile());\n        // Run REST server\n        IRestApiService restApi = moduleContext.getServiceImpl(IRestApiService.class);\n        restApi.run();\n        // Run the main floodlight module\n        IFloodlightProviderService controller =\n                moduleContext.getServiceImpl(IFloodlightProviderService.class);\n        // This call blocks, it has to be the last line in the main\n        controller.run();\n    }\n\t\n\n\n\n在main函数中，首先读取并解析命令行参数。然后从默认配置文件中加载需要加载的模块(fml.loadModulesFromConfig(settings.getModuleFile()))。默认配置文件为config/floodlight.properties，该文件保存着需要加载的模块的类的路径。追踪该函数可以发现，最终调用loadModuleFromList函数,该函数首先调用findAllModules(configMods)函数，该函数建立三个map\n\n- serviceMap -> Maps a service to a module\n- moduleServiceMap -> Maps a module to all the services it provides\n- moduleNameMap -> Maps the string name to the module\n\n其次，遍历加载每一个模块及其依赖的模块，如果该模块中提供的service被设置为ignored，则不加载该模块。\n\n在loadModulesFromList的最后调用parseConfigParameters,initModues和startpuModules函数,进行模块的配置、初始化、和启动。\n\n    parseConfigParameters(prop);\n    initModules(moduleSet);\n    startupModules(moduleSet);\n\nInitModules函数加载各个模块的service，并加入floodlightModuleContext中,最后调用每个模块的init函数\nstartpuModules函数调用每个模块的startup函数。\n\n\nMain函数，然后启动REST服务器，接收RESTful API调用。最后从moduleContext获取IFloodlightProviderService的实现类，实际上controller类（core/internal/Controller.java）实现了该接口。最后调用run函数启动controller。\n","mtime":1414675210000,"source":"_posts/Floodlight02.md"},"tixclo6n76m8f08a":{"_id":"tixclo6n76m8f08a","content":"title: Floodlight No.3\ndate: 2014/10/30 21:46:20 \ntags: \n- Floodlight\n- Controller\ncategories: Floodlight\n---\n\n## Controller (core/internal/Controller.java)(1) ##\n\n\nController类实现了IFloodlightProviderService服务。FloodlightProrider类中定义了controller的对象，作为一个模块出现。IFloodlightProviderService定义了controller和switch通信的接口。Controller类实现了控制器和交换机之间的交互。\n\n**IFloodlightProviderService服务接口**\n<!--more-->\n首先，在该接口中定义了控制器的角色，包括：EQUAL, MASTER, SLAVE。\n\n    public static final FloodlightContextStore<Ethernet> bcStore = new FloodlightContextStore<Ethernet>();\n新建FloodlightContextStore 对象，bcStore对象提供了FloodlightContext对象的操作方法，包括get，put，remove。而FloodlightContext对象实际上是一个map对象，用来存储事件的上下文信息（如packet-in payload）。\n\n    public synchronized void addOFMessageListener(OFType type, IOFMessageListener listener) {\n        ListenerDispatcher<OFType, IOFMessageListener> ldd = \n            messageListeners.get(type);\n        if (ldd == null) {\n            ldd = new ListenerDispatcher<OFType, IOFMessageListener>();\n            messageListeners.put(type, ldd);\n        }\n        ldd.addListener(type, listener);\n    }\n该函数向messageListener（map）中添加type和对应的message listener，各个模块通过该函数向控制器注册各种其关心的消息类型，当控制器收到该类型的消息后，将调用其对应的函数。\n\n    public Map<OFType, List<IOFMessageListener>> getListeners() \ngetListeners（）函数获取所有listener。\n\n    public Map<Long, IOFSwitch> getSwitches() {\n        return Collections.unmodifiableMap(this.activeSwitches);\n    }\ngetSwitches函数获取所有active交换机，但是如果controller处于slave角色，将将不包含任何switch。\n\n    public void addOFSwitchListener(IOFSwitchListener listener) {\n        this.switchListeners.add(listener);\n    }\n    public void removeOFSwitchListener(IOFSwitchListener listener) {\n        this.switchListeners.remove(listener);\n    }\n添加与删除switch的listener\n\n    public synchronized void terminate() {\n        log.info(\"Calling System.exit\");\n        System.exit(1);\n    }\n退出controller进程。\n\n    public boolean injectOfMessage(IOFSwitch sw, OFMessage msg) {\n        // call the overloaded version with floodlight context set to null    \n        return injectOfMessage(sw, msg, null);\n    }\n    ……\n    public boolean injectOfMessage(IOFSwitch sw, OFMessage msg,\n                                   FloodlightContext bc) {\n        if (sw == null) {\n            log.info(\"Failed to inject OFMessage {} onto a null switch\", msg);\n            return false;\n        }\n        if (!activeSwitches.containsKey(sw.getId())) return false;\n        try {\n            // Pass Floodlight context to the handleMessages()\n            handleMessage(sw, msg, bc);\n        } catch (IOException e) {\n            log.error(\"Error reinjecting OFMessage on switch {}\", \n                      HexString.toHexString(sw.getId()));\n            return false;\n        }\n        return true;\n    }\n重新为一个switch注入一个msg，并调用handleMessage函数处理该消息。\n\n    public void handleOutgoingMessage(IOFSwitch sw, OFMessage m, FloodlightContext bc) {\n        if (log.isTraceEnabled()) {\n            String str = OFMessage.getDataAsString(sw, m, bc);\n            log.trace(\"{}\", str);\n        }\n        List<IOFMessageListener> listeners = null;\n        if (messageListeners.containsKey(m.getType())) {\n            listeners = \n                    messageListeners.get(m.getType()).getOrderedListeners();\n        }            \n        if (listeners != null) {                \n            for (IOFMessageListener listener : listeners) {\n                if (listener instanceof IOFSwitchFilter) {\n                    if (!((IOFSwitchFilter)listener).isInterested(sw)) {\n                        continue;\n                    }\n                }\n                if (Command.STOP.equals(listener.receive(sw, m, bc))) {\n                    break;\n                }\n            }\n        }\n    }\n处理发向switch的outgoing包，调用注册了该类型OFType的listener。\n\n    public BasicFactory getOFMessageFactory();\n返回factory，该factory为BasicFactory类对象，实现了OFMessageFactory, OFActionFactory, OFStatisticsFactory, OFVendorDataFactory等，用来生成OF的message和actions。\n\n最后还有一些简单的函数\n\n    public void addInfoProvider(String type, IInfoProvider provider); //添加各种类型的信息的provider，获取服务的信息\n    public void removeInfoProvider(String type, IInfoProvider provider); //删除provider\n    public Map<String, Object> getControllerInfo(String type); //获取一种特定类型的控制器信息\n    public long getSystemStartTime();//获取系统时间\n    public void setAlwaysClearFlowsOnSwAdd(boolean value);//设置当交换机连接到控制器时，清除其流表\n","mtime":1414676832000,"source":"_posts/floodlight03.md"},"hbpb4ggintmt1t55":{"_id":"hbpb4ggintmt1t55","content":"title: Floodlight No.4\ndate: 2014/10/30 22:14:35 \ntags: \n- Floodlight\n- Controller\ncategories: Floodlight\n---\n\n## Controller (core/internal/Controller.java)(2) ##\n![控制器运行过程](/img/floodlight03-controller.png)\n\n本文主要介绍controller中的run函数，run函数的运行图如上图。\n<!--more-->\n    public void run() {\n        if (log.isDebugEnabled()) {\n            logListeners();\n        } \n        try {            \n           final ServerBootstrap bootstrap = createServerBootStrap(); //新建bootstrap server，用于与交换机之间通信\n\n            bootstrap.setOption(\"reuseAddr\", true);\n            bootstrap.setOption(\"child.keepAlive\", true);\n            bootstrap.setOption(\"child.tcpNoDelay\", true);\n            bootstrap.setOption(\"child.sendBufferSize\", Controller.SEND_BUFFER_SIZE);\n\n            ChannelPipelineFactory pfact = \n                    new OpenflowPipelineFactory(this, null);  //新建pipeline，见下详解，这里是重点\n            bootstrap.setPipelineFactory(pfact); //设置pipeline\n            InetSocketAddress sa = new InetSocketAddress(openFlowPort);\n            final ChannelGroup cg = new DefaultChannelGroup();\n            cg.add(bootstrap.bind(sa)); //开始监听\n            \n            log.info(\"Listening for switch connections on {}\", sa);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n        // main loop\n        while (true) {\n            try {\n                IUpdate update = updates.take();\n                update.dispatch();\n            } catch (InterruptedException e) {\n                return;\n            } catch (StorageException e) {\n                log.error(\"Storage exception in controller \" + \n                          \"updates loop; terminating process\", e);\n                return;\n            } catch (Exception e) {\n                log.error(\"Exception in controller updates loop\", e);\n            }\n        }\n    }\n\nFloodlight使用Netty serverBootstrap来处理与交换机之间的网络通信。在controller的run函数中，初始化serverBootstrap，并且添加Pipeline来负责处理接收到的交换机消息的处理顺序。\n\nNetty中的pipeline处理顺序分为upstream和downstream，处理时首先按照添加顺序处理upstream的handler，然后按照添加顺序的逆序处理downstream的handler。以Floodlight中的pipeline为例：\n\n    public ChannelPipeline getPipeline() throws Exception {\n        OFChannelState state = new OFChannelState();\n        \n        ChannelPipeline pipeline = Channels.pipeline();\n        pipeline.addLast(\"ofmessagedecoder\", new OFMessageDecoder());\n        pipeline.addLast(\"ofmessageencoder\", new OFMessageEncoder());\n        pipeline.addLast(\"idle\", idleHandler);\n        pipeline.addLast(\"timeout\", readTimeoutHandler);\n        pipeline.addLast(\"handshaketimeout\",\n                         new HandshakeTimeoutHandler(state, timer, 15));\n        if (pipelineExecutor != null)\n            pipeline.addLast(\"pipelineExecutor\",\n                             new ExecutionHandler(pipelineExecutor));\n        pipeline.addLast(\"handler\", controller.getChannelHandler(state));\n        return pipeline;\n    }\n- ofmessagedecoder, upstream\n- ofmessageencoder, donwtream\n- idleStateHandler upstream\n- readTimeoutHandler upstream\n- handshakeTimeoutHandler upstream\n- handler, 即of的handler，upstream\n\n因此，当一个包到时的执行顺序为Ofmessagedecoder-> IdleStateHandler-> ReadTimeoutHandler-> HandshakeTimeoutHandler-> Handler-> Ofmessageencoder。在这其中，handler是controller主要的处理逻辑。\n\n之后，主函数进入主循环。主循环主要处理一些更新，包括switchUpdate（包括add,remove,portchange），HARoleUpdate，HAControllerNodeIPUpdate。\n\n这些消息为什么要异步处理？\n\nOFChannelHandler类，该类实现一个channel handler负责处理和交换机的连接，并将接受的消息分发到合适的位置，每个OFChannelHandler对象，对应一个switch。\n\n    public void channelConnected(ChannelHandlerContext ctx, ChannelStateEvent e) throws Exception {\n            log.info(\"New switch connection from {}\",\n                     e.getChannel().getRemoteAddress());\n            \n            sw = new OFSwitchImpl();\n            sw.setChannel(e.getChannel());\n            sw.setFloodlightProvider(Controller.this);\n            sw.setThreadPoolService(threadPool);\n            \n            List<OFMessage> msglist = new ArrayList<OFMessage>(1);\n            msglist.add(factory.getMessage(OFType.HELLO));\n            e.getChannel().write(msglist);\n        }\nChannelConnected是重写函数，在交换机建立和控制器的连接时被自动调用。函数首先新建一个交换机实例，设置其通信channel，floodlightprovider和线程池。最后，发送HELLO消息。\n\n    public void channelDisconnected(ChannelHandlerContext ctx, ChannelStateEvent e) throws Exception {\n            if (sw != null && state.hsState == HandshakeState.READY) {\n                if (activeSwitches.containsKey(sw.getId())) {\n                    // It's safe to call removeSwitch even though the map might\n                    // not contain this particular switch but another with the \n                    // same DPID\n                    removeSwitch(sw);\n                }\n                synchronized(roleChanger) {\n                    connectedSwitches.remove(sw);\n                }\n                sw.setConnected(false);\n            }\n            log.info(\"Disconnected switch {}\", sw);\n        }\n    protected void removeSwitch(IOFSwitch sw) {\n                log.debug(\"removeSwitch: {}\", sw);\n        if (!this.activeSwitches.remove(sw.getId(), sw) || !sw.isConnected()) {\n            log.debug(\"Not removing switch {}; already removed\", sw);\n            return;\n        }\n        sw.cancelAllStatisticsReplies();\n            \n        updateInactiveSwitchInfo(sw);\n        SwitchUpdate update = new SwitchUpdate(sw, SwitchUpdateType.REMOVED);\n        try {\n            this.updates.put(update);\n        } catch (InterruptedException e) {\n            log.error(\"Failure adding update to queue\", e);\n        }\n    }\nchannelDisconnected函数也是重写函数，在交换机和控制器断开连接时被自动调用。该函数从两个map中移除交换机：activeSwitches和connectedSwitches。RemoveSwitch函数将交换机从activeSwitches中移除。\t在removeSwitch函数中首先调用activeSwitches.remove将其从活动交换机map中移除。然后调用cancelAllStatisticsReplies函数取消交换机所有的统计请求。updateInactiveSwitchInfo函数将非活跃状态的交换机同步到数据库。最后将交换机的移除消息放在updates中，由run函数的主循环处理更新消息的listener\n\n    public void messageReceived(ChannelHandlerContext ctx, MessageEvent e)\n                throws Exception {\n            if (e.getMessage() instanceof List) {\n                @SuppressWarnings(\"unchecked\")\n                List<OFMessage> msglist = (List<OFMessage>)e.getMessage();\n\n                for (OFMessage ofm : msglist) {\n                    try {\n                        processOFMessage(ofm);\n                    }\n                    catch (Exception ex) {\n                        Channels.fireExceptionCaught(ctx.getChannel(), ex);\n                    }\n                }\n\n                // Flush all flow-mods/packet-out generated from this \"train\"\n                OFSwitchImpl.flush_all();\n            }\n        }\nReceivemessage函数是重写函数，在交换机的channel收到消息时自动调用该函数。通过MessageEvent获取消息，消息是以List方式保存的，因此遍历消息列表，并调用processOFMessage函数处理每一个消息。最后调用flush_all将要发送消息全部发送，该函数是静态函数，会将所有交换机的消息发送。\n\n    protected void processOFMessage(OFMessage m)\n该函数处理OF消息，如果是简单消息（如HELLO或ECHO_REQUEST等）就直接处理，复杂消息会再调用handleMessage函数进行进一步处理。\n\n    protected void handleMessage(IOFSwitch sw, OFMessage m,  FloodlightContext bContext)\n在handleMessage函数中，如果消息的类型是PACKET_IN要做一个特殊处理（这里不懂），然后进入default，然后获取注册了该消息类型的所有listener，然后分别执行listener的receive函数处理该消息。具体如文章一开始的控制器运行图所示。","mtime":1414679066000,"source":"_posts/floodlight04.md"},"tvppsqo0rg97so1q":{"_id":"tvppsqo0rg97so1q","content":"title: Floodlight No.5\ndate: 2014/10/30 22:25:17 \ntags: \n- Floodlight\n- Controller\ncategories: Floodlight\n---\n\n\n## LinkDiscoverManager模块 ##\n\n    protected Command handlePacketIn(long sw, OFPacketIn pi,\n                                     FloodlightContext cntx) {\n        Ethernet eth = \n                IFloodlightProviderService.bcStore.get(cntx, \n                                                       IFloodlightProviderService.CONTEXT_PI_PAYLOAD);\n\n        if(eth.getEtherType() == Ethernet.TYPE_BSN) {\n            BSN bsn = (BSN) eth.getPayload();\n            if (bsn == null) return Command.STOP;\n            if (bsn.getPayload() == null) return Command.STOP;\n            // It could be a packet other than BSN LLDP, therefore\n            // continue with the regular processing.\n            if (bsn.getPayload() instanceof LLDP == false)\n                return Command.CONTINUE;\n            return handleLldp((LLDP) bsn.getPayload(), sw, pi, false, cntx);\n        } else if (eth.getEtherType() == Ethernet.TYPE_LLDP)  {\n            return handleLldp((LLDP) eth.getPayload(), sw, pi, true, cntx);\n        } else if (eth.getEtherType() < 1500) {\n            long destMac = eth.getDestinationMAC().toLong();\n            if ((destMac & LINK_LOCAL_MASK) == LINK_LOCAL_VALUE){\n                if (log.isTraceEnabled()) {\n                    log.trace(\"Ignoring packet addressed to 802.1D/Q \" +\n                            \"reserved address.\");\n                }\n                return Command.STOP;\n            }\n        }\n\n        // If packet-in is from a quarantine port, stop processing.\n        NodePortTuple npt = new NodePortTuple(sw, pi.getInPort());\n        if (quarantineQueue.contains(npt)) return Command.STOP;\n\n        return Command.CONTINUE;\n    }\n<!--more-->\n\n在收到PacketIn消息是，调用handlePacketIn函数，处理LLDP包。首先检查以太网包的类型，一共有两种类型。一种直接是LLDP类型，一种是BSN类型，BSN类型是bigswitch公司自定义的一种类型（BDDP包，广播包），BSN类型包的负载也可能是LLDP包，因此在函数中做判断。如果发现是LLDP包，则调用handleLldp函数进行处理。LinkDiscoverManager模块在startup函数中，启动3个线程。其实，每个交换机不是自己主动发送LLDP包的，是controller定时发送action，使所有交换机发送LLDP包，然后交换机再将受到的LLDP包以PacketIn的方式返回给controller来处理，从而维护全网的link。\n\n第一个线程是：discoveryTask，标准LLDP协议定时发现线程\n\n    discoveryTask = new SingletonTask(ses, new Runnable() {\n            @Override\n            public void run() {\n                try {\n                    discoverLinks();\n                }\n     ……\n\n    if (role == null || role == Role.MASTER) {\n            log.trace(\"Setup: Rescheduling discovery task. role = {}\", role);\n            discoveryTask.reschedule(DISCOVERY_TASK_INTERVAL, TimeUnit.SECONDS);\n        } else {\n                log.trace(\"Setup: Not scheduling LLDP as role = {}.\", role);\n        }\n    protected void discoverLinks() {\n\n        // timeout known links.\n        timeoutLinks();\n\n        //increment LLDP clock\n        lldpClock = (lldpClock + 1)% LLDP_TO_ALL_INTERVAL;\n\n        if (lldpClock == 0) {\n            log.debug(\"Sending LLDP out on all ports.\");\n            discoverOnAllPorts();\n        }\n    }\n该线程定时的（每DISCOVERY_TASK_INTERVAL秒执行一次）执行discoverLinks函数，discoverLink函数首先处理那些过时了的link（timeoutLinks），其次，每间隔LLDP_TO_ALL_INTERVAL要求全部交换机在所有端口发送LLDP包（discoverOnAllPorts）\n第二个线程是：bddpTask，LLDP广播包。\n链路发现服务使用LLDP和广播包（aka BDDPs）发现链路，LLDP的目的MAC地址是01:80:C2:00:00:0E，BDDP的目的地址是FF:FF:FF:FF:FF:FF，LLDP的以太网帧类型是0X88CC，BDDP的以太网帧类型是0X8999，链路发现服务能够正确地认知拓扑图是建立在两个假设上的：①所有的交换机都会销毁link-local packet（LLDP）②Honors layer 2 broadcasts。\n\n链路可以是直连的，也可以是广播。如果LLDP包从一个端口发出去，另外一个端口收到了相同的LLDP包，说明这两个端口是直连的，就会建立一个直连链路；如果一个BDDP包从一个端口发送，在其它的端口接收，说明在两个交换机之间有控制器无法控制的二层交换机，就会建立一个广播链路。\n\n    bddpTask = new SingletonTask(ses, new QuarantineWorker());\n    bddpTask.reschedule(BDDP_TASK_INTERVAL, TimeUnit.MILLISECONDS);\n第三个线程：updatesTread，该线程主要负责更新消息回调，如果链路或者端口发生变化，则调用已经注册的listener的回调函数，处理这些更新。\n\n    updatesThread = new Thread(new Runnable () {\n            @Override\n            public void run() {\n                while (true) {\n                    try {\n                        doUpdatesThread();\n                    } catch (InterruptedException e) {\n                        return;\n                    }\n                }\n            }}, \"Topology Updates\");\n        updatesThread.start();\n\n\n**HandleportStatus**\n\n处理port状态信息。首先判断是否要删除port或者是要关闭port，如果是这种情况，那么要删除与这个port向连的link，调用deleteLinksOnPort()函数。在该函数中，从switchLink中删除、PortLinks中删除、还有Links中删除。如果是端口修改，找到跟这个端口对应的link，然后修改对应的端口状态。\n","mtime":1414679220000,"source":"_posts/floodlight05.md"},"n0nl0s1s49au03qa":{"_id":"n0nl0s1s49au03qa","content":"title: Floodlight No.6\ndate: 2014/10/30 22:26:36 \ntags: \n- Floodlight\n- Controller\ncategories: Floodlight\n---\n\n## TopologyManager Module ##\n\n该模块接收LinkDiscover的跟新消息，当有链路跟新时，将重新计算topo。主要调用TopologyInstance类中的compute函数。compute函数即注释如下\n<!--more-->\n    public void compute() {\n\n        // Step 1: Compute clusters ignoring broadcast domain links\n        // Create nodes for clusters in the higher level topology\n        // Must ignore blocked links.\n        identifyOpenflowDomains();//利用强连通分量Tarjan算法，将topo划分强连通子树\n\n        // Step 1.1: Add links to clusters\n        // Avoid adding blocked links to clusters\n        addLinksToOpenflowDomains();//将同属于一个连通分量的switch的link添加到连通分量中\n\n        // Step 2. Compute shortest path trees in each cluster for \n        // unicast routing.  The trees are rooted at the destination.\n        // Cost for tunnel links and direct links are the same.\n        calculateShortestPathTreeInClusters();//使用dijstra算法，计算一个cluster内部的所有点最短路径\n\n        // Step 3. Compute broadcast tree in each cluster.\n        // Cost for tunnel links are high to discourage use of \n        // tunnel links.  The cost is set to the number of nodes\n        // in the cluster + 1, to use as minimum number of \n        // clusters as possible.\n        calculateBroadcastNodePortsInClusters();\n\n        // Step 4. print topology.\n        // printTopology();\n    }\n","mtime":1414679398000,"source":"_posts/floodlight06.md"},"aynkn20e5lruh8gx":{"_id":"aynkn20e5lruh8gx","content":"title: 杭州+乌镇\ndate: 2014/10/30 22:35:33 \ntags: \ncategories: Photo\n---\n\n![乌镇](/img/wuzhen1.JPG)\n<!--more-->\n![乌镇](/img/wuzhen2.JPG)\n![乌镇](/img/wuzhen3.JPG)\n![西湖](/img/xihu.jpg)\n![西湖](/img/xihu2.JPG)","mtime":1414680574000,"source":"_posts/Hangzhou.md"},"2zwwefkmobyxvkdn":{"_id":"2zwwefkmobyxvkdn","content":"title: Ryu文档-1-开始\ndate: 2014/11/5 23:39:29 \ntags: \n- Ryu\n- Controller\ncategories: Ryu\n---\n\n## 1.1 什么是Ryu ##\nRyu是一套基于组件的软件定义网络的框架。\n\nRyu提供了一套软件组件和高效的API，使网络开发者在开发网络管理控制应用时更加方便快捷。Ryu支持各种南向接口来控制网络设备，如OpenFlow，Netconf，OF-config等。Ryu支持OpenFlow 1.0，1.2，1.3，1.4版本和Nicira扩展。\n\nRyu所有源代码都是开源的，遵循 Apache 2.0 license。Ryu完全有Python编写。\n<!--more-->\n## 1.2 快速入门 ##\n\n安装Ryu非常简单，在linux命令行下输入\n\n    % pip install ryu\npip是Python包管理工具，具体可见[https://pypi.python.org/pypi/pip](https://pypi.python.org/pypi/pip \"pip\")\n\n如果你热衷于使用源码安装Ryu，可以使用Git下载源码，并安装\n\n    % git clone git://github.com/osrg/ryu.git\n    % cd ryu; python ./setup.py install\n如果你想了解在Openstack中如何使用Ryu，请参见[详细文档](http://ryu.readthedocs.org/en/latest/using_with_openstack.html)。你可以VLAN使用创建许多隔离的虚拟网络。 Ryu在Openstack的E版本中出现。\n如果你系那个要编写你自己的Ryu的应用，可以参考[Writing ryu application](http://ryu.readthedocs.org/en/latest/writing_ryu_app.html)文档。编写完成后，只需要简单的输入\n\n    % ryu-manager yourapp.py\n## 1.3 Support ##\nRyu的官方网站是[http://osrg.github.io/ryu/](http://osrg.github.io/ryu/)\n\n----------\n\n本系列文章翻译于Ryu Documentation Release 3.14，并加入自己的理解","mtime":1415202322000,"source":"_posts/RyuDoc1.md"},"qjjfijua43seewgd":{"_id":"qjjfijua43seewgd","content":"title: Ryu文档-2-2-Ryu组件\ndate: 2014/11/8 22:10:09 \ntags: \n- Ryu\n- Controller\ncategories: Ryu\n---\n\n## 2.2 Ryu组件 ##\n<!--more-->\n![Components of Ryu](/img/Componentsofryu.png)\n","mtime":1415455937000,"source":"_posts/RyuDoc2-2.md"},"g6xado17q32zg0eu":{"_id":"g6xado17q32zg0eu","content":"title: Ryu文档-2-1-第一个Ryu应用\ndate: 2014/11/8 20:04:42 \ntags: \n- Ryu\n- Controller\ncategories: Ryu\n---\n\n## 2.1 第一个Ryu应用 ##\n如果你想用自己的方式来管理网络设备，比如路由器、交换机等，你可以自己来编写一个Ryu的应用程序来实现你的想法。你的应用程序可以告诉Ryu来如何管理这些设备，然后Ryu通过OpenFlow协议来管理设备。编写Ryu应用程序非常简单，直接通过Python脚本就可以实现了。接下来我们就看看如果写一个简单的Ryu应用。\n<!--more-->\n## Dumb Switch ##\n我们首先来实现一个简单的交换机，交换机将所有的收到的包在各个端口洪泛发送。代码如下\n\n    from ryu.base import app_manager\n    from ryu.controller import ofp_event\n    from ryu.controller.handler import MAIN_DISPATCHER\n    from ryu.controller.handler import set_ev_cls\n    class L2Switch(app_manager.RyuApp):\n        def __init__(self, *args, **kwargs):\n\t\t\tsuper(L2Switch, self).__init__(*args, **kwargs)\n\t\t@set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)\n\t\tdef packet_in_handler(self, ev):\n\t\t\tmsg = ev.msg\n\t\t\tdp = msg.datapath\n\t\t\tofp = dp.ofproto\n\t\t\tofp_parser = dp.ofproto_parser\n\n\t\t\tactions = [ofp_parser.OFPActionOutput(ofp.OFPP_FLOOD)]\n\t\t\tout = ofp_parser.OFPPacketOut(\n\t\t\tdatapath=dp, buffer_id=msg.buffer_id, in_port=msg.in_port,\n\t\t\tactions=actions)\n\t\t\tdp.send_msg(out)\n\n接下来，我们分析一下这段代码。初始化函数，没有做实际的事情，不多说。我们来看一下packet\\_in\\_handler函数。每当Ryu收到OpenFlow协议中的packet\\_in消息时，这个函数就会被调用。原因一定是这个函数被注册为回调函数了。在这里的关键就是set\\_ev\\_cls装饰器。其实这个函数就是将packet\\_in\\_handler函数注册到packet\\_in消息上，每当有packet\\_in消息就调用该函数，使用装饰器使得代码显得比较简洁优美。我们来看一下这个装饰器的参数:\n\n- 第一个参数是指定触发函数被调用的事件，这里即Packet\\_in事件。\n- 第二个参数是指定交换机的状态。比如，当交换机处于与控制器协商（negotiation）阶段时,可能你想忽略此时的packet\\_in消息，那我们就可以使用MAIN\\_DISPATCHER作为参数来表明当协商完成后该函数才被调用。\n\n接下来我们来分析packet\\_in\\_handler的函数体：\nev.msg是packet\\_in的消息对象，存储着消息的数据部分\nmsg.dp代表发送该消息的交换机（datapath）\ndp.ofproto是交换机和控制器协商好的OF协议\ndp.ofproto\\_parser是OF协议的解释器，用于解析和封装符合OF协议的数据。\nOFPActionOutput函数用来生成一个action，该action指定包输出的转发端口。在我们这个应用中，交换机将包发送没每一个端口，因此使用OFPP_FLOOD常量作为参数。\nOFPPacketOut函数用来生成packet\\_out包\nsend\\_msg函数将包发送给相关的交换机\n\n到这儿，我们就完成了我们第一个Ryu应用程序。我们可以将其保存为l2.py文件，然后执行如下命令就启动我们的应用了。\n\n\t% ryu-manager l2.py\n\tloading app l2.py\n\tinstantiating app l2.py\n\n","mtime":1415455934000,"source":"_posts/RyuDoc2.md"},"9z4xojc1w6abpupq":{"_id":"9z4xojc1w6abpupq","content":"title: Ryu文档-2-2-Ryu组件\ndate: 2014/11/8 22:10:09 \ntags: \n- Ryu\n- Controller\ncategories: Ryu\n---\n\n## 2.2 Ryu组件 ##\n<!--more-->\n![Components of Ryu](/img/Componentsofryu.png)\n","mtime":1415455937000,"source":"_posts/RyuDoc3.md"},"ydqbkx54e276qvcr":{"_id":"ydqbkx54e276qvcr","content":"title: Ryu文档-2-3-Ryu组件\ndate: 2014/11/26 22:21:38 \ntags: \n- Ryu\n- Controller\ncategories: Ryu\n---\n\n# 2.3 Ryu应用的API #\n## 2.3.1 Ryu应用的编程模型 ##\n\nryu应用是单线程的实体，应用之间通过消息彼此通信。\n\nryu应用之间互相发送异步的消息。ryu的OpenFlow控制器不属于ryu应用，但也是产生消息的源头。虽然ryu的消息可以包含任意的python objects，但是并不推荐在ryu应用之间传递较大的实体。\n<!--more-->\n每个ryu应用有一个消息的接收队列，是一个FIFO队列。每个ryu应用都有一个事件处理线程，该线程不断的从接收队列冲取出消息，并根据消息类型调用相应的消息处理函数。消息处理函数似乎在实现处理线程的上下文环境中被调用的，因此必须做好阻塞。\n\nryu有很多类型的消息类型来实现ryu应用之间的异步消息。\n\ncontexts是ryu应用公用的一个objects，因此不要用于新的代码中。\n（意思contexts这个变量是内部变量？不要随便用？）\n\n## 2.3.2 创建一个Ryu应用##\n一个ryu应用是作为一个python模块的，并且继承了ryu.base.app\\_manager.RyuApp类。如果两个相同的ryu应用被定义在一个模块中，那么app\\_manager将选择第一个出现的。ryu应用是单例的，只允许有一个给定的ryu应用。\n\n## 2.3.3 如何获取ryu消息##\nryu应用通过注册的方式与消息挂钩，通过ryu.controller.handler.set\\_ev\\_cls 装饰器来注册某一个时间的处理函数。该装饰器第一个参数定义注册的消息类型，第二个参数可以指定一个接收的时间阶段（如下图），来指定在什么时候才为这个处理函数生成消息。\n\n![phase](/img/ryudoc4phase.jpg)\n\n## 2.3.4 如何生成ryu消息##\nryu应用可以使用send\\_event 或者 send\\_event\\_to\\_observers 函数发送消息\n\n## 2.3.5 事件类##\n事件类描述了ryu系统中的事件。ryu中所有的事件类都已“Event”作为前缀。消息事件可以由ryu的核心组件生成，也可以有ryu应用生成。\n\nryu.controller.ofp\\_event 模块定义了openflow消息的事件类。该类消息被规范的命名为ryu.controller.ofp\\_event.EventOFPxxxx。例如EventOFPPacketIn是OF的packet-in消息。OpenFlow控制器自通的解析Openflow消息并将消息时间发送给关心该消息类型的应用。\n\n## 2.3.6 ryu.controller.controller.Datapath##\n\n该类定义了与控制器相连的交换机的信息，类中定义的属性如下。\n\n![datapath](/img/ryudoc4dp.jpg)\n\n\n## 2.3.7 ryu.controller.event.EventBase##\n这个类是所有事件类的基类。ryu应用可以继承这个类来自定义事件类型\n\n## 2.3.8 ryu.controller.event.EventRequestBase##\n请求事件的基类\n\n## 2.3.9 ryu.controller.event.EventReplyBase##\n应答事件基类\n\n## 2.3.10 ryu.controller.ofp_event.EventOFPStateChange##\n状态变更事件\n\n## 2.3.11 ryu.controller.dpset.EventDP##\n当交换机连接到控制器或者断开与控制器的连接时产生该事件，ryu.controller.ofp_event.EventOFPStateChange 类也可以获取该事件。从该事件中可以获取关联该事件的交换机dp。\n\n## 2.3.12 ryu.controller.dpset.EventPortAdd（EventPortDelete、EventPortModify）##\n当一个交换机添加（删除，修改）新端口时产生该事件，事件包含的信息包括dp和port\n\n## 2.3.13 ryu.controller.network.EventNetworkPort##\n这个时间跟一个网络相关（可能是一个虚拟网络？），当网络中添加或者删除一个端口时，产生该事件。该事件可以获取的信息包括，network_id, dpid, port_no, 以及add_del(是添加还是删除)\n\n## 2.3.14 ryu.controller.network.EventNetworkDel##\n当一个网络被删除时产生该事件，可以获取的信息是network_id\n\n## 2.3.15 ryu.controller.network.EventMacAddress##\n当一个端口的MAC地址添加时，产生该事件，可以获取的信息包括network_id dpid port_no mac_address add_del\n\n## 2.3.16 ryu.controller.tunnels.EventTunnelKeyAdd(tunnels.EventTunnelKeyDel)##\n当一个隧道的key被注册或者更新(删除)时，产生该事件。可以获取的信息包括 network_id tunnel_key\n\n## 2.3.17 ryu.controller.tunnels.EventTunnelPort##\n当一个隧道的端口被添加或删除时产生该事件，信息包括dpid port_no remote_dpid add_del","mtime":1417098201000,"source":"_posts/RyuDoc4.md"},"2nj48ht9qve6qoye":{"_id":"2nj48ht9qve6qoye","content":"title: python-inspect模块\ndate: 2014/11/26 21:24:06 \ntags: \n- Python\ncategories: Python\n---\n\n\npython inspect模块\n\n今天看RYU源码时，发现一个inspect模块，RYU使用了该模块的getmembers函数来获取ryu app的app类。\n\n函数原型是 inspect.getmembers(object[, predicate])\n\n功能： 从一个Object中获取符合predicate的元素的list，元素的形式是（name，value）\npredicate可以是ismodule(), isclass(), ismethod(), isfunction(), isgeneratorfunction(), \nisgenerator(), istraceback(), isframe(), iscode(), isbuiltin(),isroutine()，这些验证函数。\n\n<!--more-->\n\n看一个例子\n\n    import inspect\n\n    class C():\n\n\t\tclass CC():\n\t\t\tdef foo3():\n\t\t\tprint \"foo3\"\n\n\t    def foo():\n\t    \tprint \"foo\"\n\t\t\n\t\tdef foo2():\n\t\t\tprint \"foo2\"\n\t\t\n\t\t\n\tcls = inspect.getmembers(C,inspect.ismethod)\n\tprint cls\n\n\n执行的结果是\n![phase](/img/python-inspect-result.jpg)\n","mtime":1417017395000,"source":"_posts/python-inspect.md"},"j4leqfno1v4czduv":{"_id":"j4leqfno1v4czduv","content":"title: python-setdefault\ndate: 2014/11/26 21:43:19 \ntags: \n- Python\ncategories: Python\n---\n\npython 字典的setdefault\n\n这个函数很好用\n当我们向字典添加元素时，可能会遇到如果key存在和不存在时，进行的赋值不一样。我过去的做法时\n\n\td = dict()\n\ta='key'\n    if a in d.keys():\n\t\tpass\n    else:\n\t\td[a] = 1\n\n现在一行搞定\n\n    d.setdefault(a,1)","mtime":1417271274000,"source":"_posts/python-setdefault.md"},"99btpliyec4o0ppl":{"_id":"99btpliyec4o0ppl","content":"title: Ryu代码解析（一）\ndate: 2014/11/27 22:21:10 \ntags: \n- Ryu\n- Controller\ncategories: Ryu\n---\n\n## RYU main函数 ##\nRyu的main函数位于cmd\\manager.py文件中，main函数如下：\n\n\tdef main(args=None, prog=None):\n\t    try:\n\t        CONF(args=args, prog=prog,\n\t             project='ryu', version='ryu-manager %s' % version,\n\t             default_config_files=['/usr/local/etc/ryu/ryu.conf'])\n\t    except cfg.ConfigFilesNotFoundError:\n\t        CONF(args=args, prog=prog,\n\t             project='ryu', version='ryu-manager %s' % version)\n\t\n\t    log.init_log()\n\t\n\t    if CONF.pid_file:\n\t        import os\n\t        with open(CONF.pid_file, 'w') as pid_file:\n\t            pid_file.write(str(os.getpid()))\n\t\n\t    app_lists = CONF.app_lists + CONF.app //从用户命令行获取的app列表\n\t    # keep old behaivor, run ofp if no application is specified.\n\t    if not app_lists:\n\t        app_lists = ['ryu.controller.ofp_handler'] //添加默认的应用\n\t\n\t    app_mgr = AppManager.get_instance() //获取appManager实例，是单体类\n\t    app_mgr.load_apps(app_lists) //加载所有app\n\t    contexts = app_mgr.create_contexts() //加载context\n\t    services = []\n\t    services.extend(app_mgr.instantiate_apps(**contexts)) //以context作为参数，实例化app\n\t\n\t    webapp = wsgi.start_service(app_mgr)\n\t    if webapp:\n\t        thr = hub.spawn(webapp)\n\t        services.append(thr)\n\t\n\t    try:\n\t        hub.joinall(services)\n\t    finally:\n\t        app_mgr.close()\n<!--more-->\n## AppManager ##\nAppManager中get_instance()函数，典型的单体类实现方法\n\n\t def get_instance():\n        if not AppManager._instance:\n            AppManager._instance = AppManager()\n        return AppManager._instance\n\n\nload\\_app函数：加载app，本质是找到app名字对应的类\n用到的python 基础：[inspect.getmembers()](https://docs.python.org/2/library/inspect.html#inspect.getmembers)和[inspect例子](http://geekwei.com/2014/11/26/python-inspect/)\n\n\tdef load_app(self, name):\n        mod = utils.import_module(name)\n        clses = inspect.getmembers(mod,\n                                   lambda cls: (inspect.isclass(cls) and\n                                                issubclass(cls, RyuApp) and\n                                                mod.__name__ ==\n                                                cls.__module__)) //过滤函数是lambda表达式\n        if clses:\n            return clses[0][1] //只与符合条件的第一个！！！文档里就这么要求的\n        return None\n\nload\\_apps函数：加载app，说是加载，其实就是找到这个类，并把其存到applications\\_cls中，key是app类的名字，值就是这个类，加载的过程中顺便加载每个app依赖的app类，而且把每个app的context保存到context\\_cls中。\n\npython 基础 [python map函数浅析](http://my.oschina.net/zyzzy/blog/115096)\n\n\tdef load_apps(self, app_lists):\n        app_lists = [app for app\n                     in itertools.chain.from_iterable(app.split(',')\n                                                      for app in app_lists)]\n        while len(app_lists) > 0:\n            app_cls_name = app_lists.pop(0)\n\n            context_modules = map(lambda x: x.__module__,\n                                  self.contexts_cls.values()) //获取所有context类所在的模块\n            if app_cls_name in context_modules: //不加载属于context的类，因为之后在create_context函数中会加载\n                continue\n\n            LOG.info('loading app %s', app_cls_name)\n\n            cls = self.load_app(app_cls_name) //找到app的类，cls就是这个app的类\n            if cls is None:\n                continue\n\n            self.applications_cls[app_cls_name] = cls //将app添加到字典\n\n            services = []\n            for key, context_cls in cls.context_iteritems(): //便利这个app类的context，将其context加入contexts_cls字典\n                v = self.contexts_cls.setdefault(key, context_cls)\n                assert v == context_cls\n                context_modules.append(context_cls.__module__)\n\n                if issubclass(context_cls, RyuApp): //感觉这里写错了，其实context的类在之后会加载，和前面的描述不符\n                    services.extend(get_dependent_services(context_cls))\n\n            # we can't load an app that will be initiataed for\n            # contexts.\n            for i in get_dependent_services(cls): //加载这个app的依赖app，依赖app不在context_modules字典中\n                if i not in context_modules:\n                    services.append(i)\n            if services:\n                app_lists.extend([s for s in set(services)\n                                  if s not in app_lists]) //将依赖的app都加入app_lists,在之后的循环中加载\n\ncreate\\_contexts函数：实例化context\\_cls中的context，如果这个context是app，就实例化该app。记得在load_apps中没有管属于context\\_cls的app吗，在这里直接初始化了。\n\n\t def create_contexts(self):\n        for key, cls in self.contexts_cls.items():\n            if issubclass(cls, RyuApp):\n                # hack for dpset\n                context = self._instantiate(None, cls) //初始化app\n            else:\n                context = cls() //实例化context\n            LOG.info('creating context %s', key)\n            assert key not in self.contexts\n            self.contexts[key] = context //加入contexts字典\n        return self.contexts //返回contexts字典\n\n_instantiate函数：\n\n\tdef _instantiate(self, app_name, cls, *args, **kwargs):\n        # for now, only single instance of a given module\n        # Do we need to support multiple instances?\n        # Yes, maybe for slicing.\n        LOG.info('instantiating app %s of %s', app_name, cls.__name__)\n\n        if hasattr(cls, 'OFP_VERSIONS') and cls.OFP_VERSIONS is not None:\n            ofproto_protocol.set_app_supported_versions(cls.OFP_VERSIONS)\n\n        if app_name is not None:\n            assert app_name not in self.applications\n        app = cls(*args, **kwargs) //实例化app类，kwargs参数是context字典\n        register_app(app) //注册app对象，主要是通过inspect组件获取其中的handler，详见下文\n        assert app.name not in self.applications\n        self.applications[app.name] = app //将app对象保存到applications字典中\n        return app\n\nregister\\_app函数中调用regester\\_instance函数（该函数在handler.py文件中）,在该函数中通过inspect.getmembers函数，获取app类中的方法，并通过app的register_handler将handler注册到app的event_handlers成员变量中\n\n\tdef register_instance(i):\n\t    for _k, m in inspect.getmembers(i, inspect.ismethod):\n\t        # LOG.debug('instance %s k %s m %s', i, _k, m)\n\t        if _has_caller(m):\n\t            for ev_cls, c in m.callers.iteritems():\n\t                i.register_handler(ev_cls, m)\n\n到这儿可能还比较迷惑，handler是如何挂到每个事件上的，将在后面的[Ryu事件处理函数的挂接方式分析](http://geekwei.com/2014/12/01/ryu-source-analysis-2md/)中专门介绍一下。\n\ninstantiate\\_apps函数：实例化app，并且启动每个app\n\n\tdef instantiate_apps(self, *args, **kwargs):\n        for app_name, cls in self.applications_cls.items():\n            self._instantiate(app_name, cls, *args, **kwargs)\n\n        self._update_bricks() //将app更新到全局变量SERVICE_BRICK中\n        self.report_bricks()\n\n        threads = []\n        for app in self.applications.values():\n            t = app.start() //启动APP\n            if t is not None:\n                threads.append(t)\n        return threads","mtime":1417527172000,"source":"_posts/ryu-source-analysis-1.md"},"qe6k2yy02j93s6sk":{"_id":"qe6k2yy02j93s6sk","content":"title: Ryu代码解析（二）\ndate: 2014/12/1 0:20:33 \ntags: \n- Ryu\n- Controller\ncategories: Ryu\n---\n\n\n## Ryu事件处理函数的挂接方式分析 ##\n\nRyu支持用户自定义事件处理函数，当该事件发生时，用户定义的处理函数会被自动的调用。那么这个机制具体是如何实现的呢？本篇博客就针对该问题，做一个简单的梳理，才疏学浅，欢迎指正！\n\n首先来看RYU文档中的那个第一个APP程序：\n\n\tfrom ryu.base import app_manager\n    from ryu.controller import ofp_event\n    from ryu.controller.handler import MAIN_DISPATCHER\n    from ryu.controller.handler import set_ev_cls\n\n    class L2Switch(app_manager.RyuApp):\n        def __init__(self, *args, **kwargs):\n\t\t\tsuper(L2Switch, self).__init__(*args, **kwargs)\n\n\t\t@set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)\n\t\tdef packet_in_handler(self, ev):\n\t\t\tmsg = ev.msg\n\t\t\tdp = msg.datapath\n\t\t\tofp = dp.ofproto\n\t\t\tofp_parser = dp.ofproto_parser\n\n\t\t\tactions = [ofp_parser.OFPActionOutput(ofp.OFPP_FLOOD)]\n\t\t\tout = ofp_parser.OFPPacketOut(\n\t\t\tdatapath=dp, buffer_id=msg.buffer_id, in_port=msg.in_port,\n\t\t\tactions=actions)\n\t\t\tdp.send_msg(out)\n\n<!--more-->\n这段代码中有两个关键的地方，第一是L2Switch类继承了app\\_manager.RyuAPP类（这是自定义APP要求的）。第二个使用set_ev_cls装饰器装饰了我们自定义的事件处理函数packet\\_in\\_handler.\n\n首先，我们来研究一下set\\_ev\\_cls装饰器到底做了些什么事情？ set\\_ev\\_cls函数定义如下：\n\n\tdef set_ev_cls(ev_cls, dispatchers=None):\n\t    def _set_ev_cls_dec(handler):\n\t        if 'callers' not in dir(handler):\n\t            handler.callers = {}\n\t        for e in _listify(ev_cls):\n\t            handler.callers[e] = _Caller(_listify(dispatchers), e.__module__)\n\t        return handler\n\t    return _set_ev_cls_dec\n\n首先这个装饰器是带参数的装饰器，在使用@set\\_ev\\_cls修饰packet\\_in\\_hander函数是，实际的过程是：\n\n**packet\\_in\\_handler=set\\_ev\\_cls(ofp\\_event.EventOFPPacketIn, MAIN\\_DISPATCHER)(packet\\_in\\_handler)**\n\n其实就是将packet\\_in\\_handler作为参数传入了\\_set\\_ev\\_cls\\_dec函数，做了一些事情之后，又把packet\\_in\\_handler返回回来。那么\\_set\\_ev\\_cls\\_dec函数做了什么呢，其实很简单。\n\n\t if 'callers' not in dir(handler): \n\t            handler.callers = {}\n\t        for e in _listify(ev_cls):\n\t            handler.callers[e] = _Caller(_listify(dispatchers), e.__module__)\n\n首先判断handler函数中有没有callers属性，函数还可以有属性？是的，举个例子\n\n\tdef foo():\n\t\tprint \"I am a function\"\n\n\tfoo.attr = 1\n\tprint foo.attr\n\n结果会输出1.\n\n因为一个handler可能会被多个装饰器装饰，所以先判断有没有该属性，没有的话新建一个字典。ev\\_cls就是传进来的ofp\\_event.EventOFPPacketIn类，OPF事件类是在不同的OF协议中实现的（如在OF1.4文件ofproto\\_1\\_4\\_parser中）。这里他把事件类转化为list，这里不懂为什么要转为为list，难道还有多个子事件？不过怎么样，这里将在caller属性中添加一个元素，key是事件类型，value是一个\\_Caller对象，该对象主要就是记下dispatchers，和这个事件的模块名。\n\n\tclass _Caller(object):\n\t    \"\"\"Describe how to handle an event class.\n\t    \"\"\"\n\t\n\t    def __init__(self, dispatchers, ev_source):\n\t        \"\"\"Initialize _Caller.\n\t\n\t        :param dispatchers: A list of states or a state, in which this\n\t                            is in effect.\n\t                            None and [] mean all states.\n\t        :param ev_source: The module which generates the event.\n\t                          ev_cls.__module__ for set_ev_cls.\n\t                          None for set_ev_handler.\n\t        \"\"\"\n\t        self.dispatchers = dispatchers\n\t        self.ev_source = ev_source\n\n到这里set\\_ev\\_cls装饰器就分析完了，回想一下它到底做了什么？其实很简单，就是给handler函数添加了一个属性callers，然后在callers中保存了该handler关心的事件类型和dispatchers。\n\n其实到这里，并没有和系统运行过程中的消息路由关联起来，我们接着往下看。\n\n还记得在[代码分析(一)](http://geekwei.com/2014/11/27/ryu-source-analysis-1/#more)中讲的main函数么，该函数在加载了app之后，调用了instantiate\\_apps()函数,该函数对每个app进行初始化。\n\n\tdef instantiate_apps(self, *args, **kwargs):\n        for app_name, cls in self.applications_cls.items():\n            self._instantiate(app_name, cls, *args, **kwargs)\n\n        self._update_bricks()\n        self.report_bricks()\n\n        threads = []\n        for app in self.applications.values():\n            t = app.start()\n            if t is not None:\n                threads.append(t)\n        return threads\n\n在该函数中，首先调用\\_instantiate实例化app，并且调用regeister\\_app()函数，\n\n\tdef register_app(app):\n\t    assert isinstance(app, RyuApp)\n\t    assert app.name not in SERVICE_BRICKS\n\t    SERVICE_BRICKS[app.name] = app\n\t    register_instance(app)\n\n该函数有两行关键代码，第一将app加入 SERVICE_BRICKS中， SERVICE_BRICKS是一个全局变量，记录着所有的app实例，之后的代码中会用到它，暂且记住。之后调用register\\_instance(app)函数（该函数在handler.py中定义）\n\t\n\tdef register_instance(i):\n\t    for _k, m in inspect.getmembers(i, inspect.ismethod):\n\t        # LOG.debug('instance %s k %s m %s', i, _k, m)\n\t        if _has_caller(m):\n\t            for ev_cls, c in m.callers.iteritems():\n\t                i.register_handler(ev_cls, m)\n\n\tdef register_handler(self, ev_cls, handler):\n        assert callable(handler)\n        self.event_handlers.setdefault(ev_cls, [])\n        self.event_handlers[ev_cls].append(handler)\n\n该函数首先使用inspect遍历该app中的所有方法，然后通过\\_has\\_caller方法判断该方法是否有“caller”属性，上文中介绍了使用装饰器函数set\\_ev\\_cls时为每一个handler函数添加了caller属性，因此这里就是遍历所有的handler函数，将callers中保存的事件及函数（ev\\_cls,m）保存在app类的event\\_handlers属性中。\n\n接下来调用\\_update\\_bricks函数, 这个函数非常重要\n\n\t def _update_bricks(self):\n        for i in SERVICE_BRICKS.values():\n            for _k, m in inspect.getmembers(i, inspect.ismethod):\n                if not hasattr(m, 'callers'):\n                    continue\n                for ev_cls, c in m.callers.iteritems():\n                    if not c.ev_source:\n                        continue\n\n                    brick = _lookup_service_brick_by_mod_name(c.ev_source)\n                    if brick:\n                        brick.register_observer(ev_cls, i.name,\n                                                c.dispatchers)\n\n                    # allow RyuApp and Event class are in different module\n                    for brick in SERVICE_BRICKS.itervalues():\n                        if ev_cls in brick._EVENTS:\n                            brick.register_observer(ev_cls, i.name,\n                                                    c.dispatchers)\n\n这里有一个技巧，其实c.ev_source如果是的module那么就是ofp\\_event,而OFPHandler类的名字正好就是'ofp\\_event'（在下文中会看到其实就是OpenFlowController）,所以这里的brick就是OFPHandler，然后将将每种ev\\_cls的类型和app名字注册到该类中，其实本质上就是OFPHandler作为了一个消息源。这个函数非常重要，将每个app的handler与消息源OFPHandler建立了联系\n\n还是没将其与系统消息路由挂起来啊！接着往下看\n\n在main函数中ryu会将所有app都启动，启动后就进入\\_event\\_loop循环\n\tdef _event_loop(self):\n        while self.is_active or not self.events.empty():\n            ev, state = self.events.get()\n            if ev == self._event_stop:\n                continue\n            handlers = self.get_handlers(ev, state)\n            for handler in handlers:\n                handler(ev)。\n\n其中一个特殊的app是opf\\_handler app，其重写了start函数，其实调用start后就是启动OpenFlowController类，OpenFlowController启动后，ryu开始监听来自交换机的新连接，当有一个新连接时，就调用datapath\\_connection\\_factory函数创建一个新的datapath对象，对象中保存着对端交换机的通信socket和address。如果交换机发来新的消息，该datapath对象在\\_recv\\_loop方法中就会获取该消息，\n\n\tdef _recv_loop(self):\n        buf = bytearray()\n        required_len = ofproto_common.OFP_HEADER_SIZE\n\n        count = 0\n        while self.is_active:\n            ret = self.socket.recv(required_len)\n            if len(ret) == 0:\n                self.is_active = False\n                break\n            buf += ret\n            while len(buf) >= required_len:\n                (version, msg_type, msg_len, xid) = ofproto_parser.header(buf)\n                required_len = msg_len\n                if len(buf) < required_len:\n                    break\n\n                msg = ofproto_parser.msg(self,\n                                         version, msg_type, msg_len, xid, buf)\n                # LOG.debug('queue msg %s cls %s', msg, msg.__class__)\n                if msg:\n                    ev = ofp_event.ofp_msg_to_ev(msg)\n    **********************************我们关注这里 开始************************************\n                    self.ofp_brick.send_event_to_observers(ev, self.state)\n    **********************************我们关注这里 结束************************************\n                    dispatchers = lambda x: x.callers[ev.__class__].dispatchers\n                    handlers = [handler for handler in\n                                self.ofp_brick.get_handlers(ev) if\n                                self.state in dispatchers(handler)]\n                    for handler in handlers:\n                        handler(ev)\n    \n                buf = buf[required_len:]\n                required_len = ofproto_common.OFP_HEADER_SIZE\n\n                # We need to schedule other greenlets. Otherwise, ryu\n                # can't accept new switches or handle the existing\n                # switches. The limit is arbitrary. We need the better\n                # approach in the future.\n                count += 1\n                if count > 2048:\n                    count = 0\n                    hub.sleep(0)\n\n\n首先通过lambda表达式定义了一个函数dispatchers，该函数获取handler的callers属性中ev事件的dispatchers。\n\n接着使用生成器，首先opf\\_brick定义如下：\n\n\t self.ofp_brick = ryu.base.app_manager.lookup_service_brick('ofp_event')\n\n还记得我们上边提到的SERVICE\\_BRICK么，lookup\\_service\\_brick('ofp_event')函数\n\n\tdef lookup_service_brick(name):\n    \treturn SERVICE_BRICKS.get(name)\n\nofp\\_brick就是ofp\\_hander对象，然后调用send\\_event\\_to\\_observers函数，将事件发送到关心该事件和该状态（由dispachers判断）的类中。\n\n\tdef send_event_to_observers(self, ev, state=None):\n        \"\"\"\n        Send the specified event to all observers of this RyuApp.\n        \"\"\"\n\n        for observer in self.get_observers(ev, state):\n            self.send_event(observer, ev, state)\n\n这里就用到了上文中提到的通过\\_update\\_brick函数填充的ovservers，然后通过send\\_event函数发送到每个ovserver的app的event队列中，然后每个app在其\\_event\\_loop中就可以获取该事件了！\n\n","mtime":1417365107000,"source":"_posts/ryu-source-analysis-2md.md"},"pwdxdgy4hti8skj8":{"_id":"pwdxdgy4hti8skj8","content":"\ntitle: Ryu代码解析（三）\ndate: 2014/12/2 21:35:13 \ntags: \n- Ryu\n- Controller\ncategories: Ryu\n---\n\n## RyuApp基类 ##\n\n**\\_CONTEXTS**\n\n该变量是RyuApp基类中定义的上下文字典，app子类来填充这个变量。该变量用来说明子类想要使用的上下文模块。但是这个上下文模块的初始化是由AppManager来做的，而且相同的上下文模块对象在不同的app子类之间是共享的。例如：\n\n\t _CONTEXTS = {\n            'network': network.Network\n        }\n\n        def __init__(self, *args, *kwargs):\n\t\t\t// 这里的kwargs就是传进来的共享的上下文，然后获取其中的‘network’来初始化每个子类中的关心的上下文变量\n            self.network = kwargs['network'] \n<!--more-->\n**\\_EVENTS**\n\nA list of event classes which this RyuApp subclass would generate.This should be specified if and only if event classes are defined in a different python module from the RyuApp subclass is.\n\n暂时不太懂怎么用，请懂的朋友留言指点。\n\n**init函数**：初始化成员变量\n\n\tdef __init__(self, *_args, **_kwargs):\n        super(RyuApp, self).__init__()\n        self.name = self.__class__.__name__\n        self.event_handlers = {}        # ev_cls -> handlers:list 事件处理函数字典key是事件，value是处理函数\n        self.observers = {}     # ev_cls -> observer-name -> states:set key是消息类，value是关注该消息的app\n        self.threads = [] #线程句柄\n        self.events = hub.Queue(128)\n        if hasattr(self.__class__, 'LOGGER_NAME'):\n            self.logger = logging.getLogger(self.__class__.LOGGER_NAME)\n        else:\n            self.logger = logging.getLogger(self.name)\n        self.CONF = cfg.CONF\n\n        # prevent accidental creation of instances of this class outside RyuApp\n        class _EventThreadStop(event.EventBase):\n            pass\n        self._event_stop = _EventThreadStop()\n        self.is_active = True #激活\n\n**start函数**：启动该app，新建一个线程，线程执行\\_event\\_loop函数\n\n \tdef start(self):\n        \"\"\"\n        Hook that is called after startup initialization is done.\n        \"\"\"\n        self.threads.append(hub.spawn(self._event_loop))\n\n**\\_event\\_loop函数**： app主线程执行的函数，从消息队列event中取出事件，并根据事件类型调用不同的处理函数\n\n\tdef _event_loop(self):\n        while self.is_active or not self.events.empty():\n            ev, state = self.events.get()\n            if ev == self._event_stop:\n                continue\n            handlers = self.get_handlers(ev, state) #从event_handlers成员变量中获得key是ev类型的处理函数，而且处理函数的_dispatcher要符合当前的state才会返回该handler。\n            for handler in handlers:\n                handler(ev)\n\n**stop函数**：停止app主线程\n\n\tdef stop(self):\n        self.is_active = False\n        self._send_event(self._event_stop, None)\n        hub.joinall(self.threads)\n\n**register\\_handler**:注册处理函数,保存在event\\_handlers变量中，key是事件类，value是一个list，保存关注该事件的处理函数，关注同一个事件的处理函数可能有多个所以保存在list中。\n\n\tdef register_handler(self, ev_cls, handler):\n        assert callable(handler)\n        self.event_handlers.setdefault(ev_cls, [])\n        self.event_handlers[ev_cls].append(handler)\n\n**unregister\\_handler**: 注销处理函数，具体操作为从event\\_handlers中删除该handler\n\n\tdef unregister_handler(self, ev_cls, handler):\n        assert callable(handler)\n        self.event_handlers[ev_cls].remove(handler)\n        if not self.event_handlers[ev_cls]:\n            del self.event_handlers[ev_cls]\n**register\\_observer**函数：该函数的主要作用是注册某个事件的观察者app（observer）。观察者的主要用途是，当本app收到一个事件时，会将该事件发送到注册的关心该事件的观察者的event队列中。主要是ofp\\_handler调用该函数来注册各种app，从而将其接受到的事件发送给各app\n\n\t def register_observer(self, ev_cls, name, states=None):\n        states = states or set()\n        ev_cls_observers = self.observers.setdefault(ev_cls, {})\n        ev_cls_observers.setdefault(name, set()).update(states)\n\n**unregister\\_observer**函数：将app从ev\\_cls事件的观察者set中去除。\n\n\tdef unregister_observer(self, ev_cls, name):\n        observers = self.observers.get(ev_cls, {})\n        observers.pop(name)\n\n**observe\\_event**函数：向提供ev\\_cls事件的app注册本app为ev_cls的观察者，这个函数跟上面的不同的是让其他的app注册自己为一个观察者。\n\n\t def observe_event(self, ev_cls, states=None):\n        brick = _lookup_service_brick_by_ev_cls(ev_cls)\n        if brick is not None:\n            brick.register_observer(ev_cls, self.name, states)\n\n**observe\\_event**函数：从提供ev\\_cls事件的app的观察者列表中删除本app。\n\n\tdef unobserve_event(self, ev_cls):\n        brick = _lookup_service_brick_by_ev_cls(ev_cls)\n        if brick is not None:\n            brick.unregister_observer(ev_cls, self.name)\n\nget_handlers函数: 该函数主要功能是获取 交换机处于state状态时的ev事件的处理函数。在当某一个app编写一个handler的时候使用se\\_ev\\_cls装饰器时，就指定了该处理函数处理的事件以及其关心的dispatcher（也就是这里的state），因此当调用get\\_handlers函数时，state和处理函数定义的dispatcher不符合时，就不包括该处理函数了。如果state是空，则返回ev的所有处理函数。\n\n\tdef get_handlers(self, ev, state=None):\n        \"\"\"Returns a list of handlers for the specific event.\n\n        :param ev: The event to handle.\n        :param state: The current state. (\"dispatcher\")\n                      If None is given, returns all handlers for the event.\n                      Otherwise, returns only handlers that are interested\n                      in the specified state.\n                      The default is None.\n        \"\"\"\n        ev_cls = ev.__class__\n\t\t#先不管state，先获取事件的处理函数\n        handlers = self.event_handlers.get(ev_cls, [])\n        if state is None:\n            return handlers\n\t\t# 该函数判断处理函数 h 是否关心处于state状态的时间，如果关心则返回true\n        def test(h): \n            if not hasattr(h, 'callers') or ev_cls not in h.callers:\n                # dynamically registered handlers does not have\n                # h.callers element for the event.\n                return True\n            states = h.callers[ev_cls].dispatchers\n            if not states:\n                # empty states means all states\n                return True\n            return state in states\n\n\t\t\\#使用filter函数，过滤符合state条件的处理函数，并返回\n        return filter(test, handlers)\n\n**get\\_getobservers函数：**获取observers中保存的所有的观察者。\n\n\t def get_observers(self, ev, state):\n        observers = []\n        for k, v in self.observers.get(ev.__class__, {}).iteritems():\n            if not state or not v or state in v:\n                observers.append(k)\n\n        return observers\n\n**send\\_request**函数：发送一个同步的请求。seq是一个EventRequestBase的实例，sync属性设置为真，表示为同步请求，回复结果保存在reply\\_q队列中，通过send\\_event函数发送给req.dst，然后阻塞自己更待回复。\n\n\n\tdef send_request(self, req):\n        \"\"\"\n        Make a synchronous request.\n        Set req.sync to True, send it to a Ryu application specified by\n        req.dst, and block until receiving a reply.\n        Returns the received reply.\n        The argument should be an instance of EventRequestBase.\n        \"\"\"\n\n        assert isinstance(req, EventRequestBase)\n        req.sync = True\n        req.reply_q = hub.Queue()\n        self.send_event(req.dst, req)\n        # going to sleep for the reply\n        return req.reply_q.get()\n\n**send\\_event**函数: 发送事件ev给名叫name的app实例。\n\n\tdef send_event(self, name, ev, state=None):\n        \"\"\"\n        Send the specified event to the RyuApp instance specified by name.\n        \"\"\"\n\n        if name in SERVICE_BRICKS:\n            if isinstance(ev, EventRequestBase):\n                ev.src = self.name #发送的事件的源设置为自己\n            LOG.debug(\"EVENT %s->%s %s\" %\n                      (self.name, name, ev.__class__.__name__))\n            SERVICE_BRICKS[name]._send_event(ev, state) #获取名字为name的app实例，调用其_send_event函数将事件加入其事件队列，我觉得函数名应该叫_add_event更加贴切\n        else:\n            LOG.debug(\"EVENT LOST %s->%s %s\" %\n                      (self.name, name, ev.__class__.__name__))\n\n\tdef _send_event(self, ev, state):\n        self.events.put((ev, state)) #将事件加入事件队列\n\nsend\\_event\\_to\\_observers函数:将事件发送给observers中的app实例。\n\n\tdef send_event_to_observers(self, ev, state=None):\n        \"\"\"\n        Send the specified event to all observers of this RyuApp.\n        \"\"\"\n\n        for observer in self.get_observers(ev, state):\n            self.send_event(observer, ev, state)\n\nreply\\_to\\_request函数：这个是send_request函数的应答函数，将rep回复发送给req端。\n\n\tdef reply_to_request(self, req, rep):\n        \"\"\"\n        Send a reply for a synchronous request sent by send_request.\n        The first argument should be an instance of EventRequestBase.\n        The second argument should be an instance of EventReplyBase.\n        \"\"\"\n\n        assert isinstance(req, EventRequestBase)\n        assert isinstance(rep, EventReplyBase)\n        rep.dst = req.src\n        if req.sync:\n            req.reply_q.put(rep)\n        else:\n            self.send_event(rep.dst, rep)\n\nclose函数：关闭app函数，什么都没做。\n\n\t def close(self):\n        \"\"\"\n        teardown method.\n        The method name, close, is chosen for python context manager\n        \"\"\"\n        pass","mtime":1417611458000,"source":"_posts/ryu-source-analysis-3.md"},"xozh11k9jdfb5ho2":{"_id":"xozh11k9jdfb5ho2","content":"title: Ryu代码解析（四）\ndate: 2014/12/4 19:38:14 \ntags: \n- Ryu\n- Controller\ncategories: Ryu\n---\n\n## Ryu OFPHandler类 ##\n\n\tclass OFPHandler(ryu.base.app_manager.RyuApp):\n\nOFPHandler类也是RyuApp的子类，但它是一个特殊的app，负责处理OF协议的相关的事件，同时将事件发送给不同的app。\n\n\tdef __init__(self, *args, **kwargs):\n        super(OFPHandler, self).__init__(*args, **kwargs)\n\t\t//这里将OFPHandler类的名字定义为ofp_event，后面会用到\n        self.name = 'ofp_event' \n<!--more-->\n**start函数**：与其他app不同的是，OFPHandler重载了start函数，首先调用父类的start函数，父类的start函数主要是轮询本app中的事件，但是貌似OFPHandler app并通过这个线程处理事件？？然后启动另一个线程OpenFlowController线程，该线程就是ryu控制器的监听线程，负责接受交换机的连接。\n\n\t def start(self):\n\t\t//调用基类RyuApp的start函数，启动轮询事件的线程\n        super(OFPHandler, self).start() \n\t\t//启动OpenFlowController线程\n        return hub.spawn(OpenFlowController())\n\n我们知道，普通的Ryu app通过set\\_ev_cls装饰器来定义事件的处理函数，尤其是Packet\\_In事件，但是对于控制器与交换机建立连接并且彼此交换配置信息时的处理函数是通过set\\_ev\\_handler来定义的。在OFPHandler中定义了这些处理函数。\n\n**set\\_ev\\_handler**函数与set\\_ev_cls的定义几乎一模一样，但是在为每个事件新建\\_Caller对象时，ev_source为空。\n\n\tdef set_ev_handler(ev_cls, dispatchers=None):\n\t    def _set_ev_cls_dec(handler):\n\t        if 'callers' not in dir(handler):\n\t            handler.callers = {}\n\t        for e in _listify(ev_cls):\n\t            handler.callers[e] = _Caller(_listify(dispatchers), None) #只有这一行不同\n\t        return handler\n    return _set_ev_cls_dec\n\n**hello_handler**函数：计算出switch和controller都支持的最大的OF版本，并且发送features\\_request请求（来获取交换机的基本性能，详细结构如下图），同时将该交换机的datapath的state设置为（CONFIG_DISPATCHER）。datapath为交换机在控制器中的一个对象，负责记录交换机的属性以及与交换机通信（接受，发送消息），详见[Ryu代码解析（五）](http://geekwei.com/2014/12/09/ryu-source-analysis-5/)\n\n\tdef hello_handler(self, ev):\n        self.logger.debug('hello ev %s', ev)\n        msg = ev.msg\n        datapath = msg.datapath\n\n        # check if received version is supported.\n        # pre 1.0 is not supported\n        elements = getattr(msg, 'elements', None)\n        if elements:\n           //这里省略了代码，这段代码根据Hello消息中的elements来确定OF的版本\n        else:\n           //这里省略了代码，这段代码根据Hello消息头中的version字段来确定OF版本\n\n        if not usable_versions:\n            error_desc = (\n                'unsupported version 0x%x. '\n                'If possible, set the switch to use one of the versions %s' % (\n                    msg.version, sorted(datapath.supported_ofp_version)))\n            self._hello_failed(datapath, error_desc)\n            return\n\t\t\n        datapath.set_version(max(usable_versions))\n\n        # now send feature\n        features_reqeust = datapath.ofproto_parser.OFPFeaturesRequest(datapath)\n        datapath.send_msg(features_reqeust)\n\n        # now move on to config state\n        self.logger.debug('move onto config mode')\n\t\t//设置交换机 datapath的状态\n        datapath.set_state(CONFIG_DISPATCHER)\n\n![Features_Reauest](/img/ryu-source-analysis-4-features.jpg)\n\n**switch\\_features\\_handler**函数：features回复消息的处理函数，但是没看到保存收到的features信息，只保存了datapath的id。然后发送switch config消息。\n\n\t def switch_features_handler(self, ev):\n        msg = ev.msg\n        datapath = msg.datapath\n        self.logger.debug('switch features ev %s', msg)\n\n        datapath.id = msg.datapath_id\n\n        # hacky workaround, will be removed. OF1.3 doesn't have\n        # ports. An application should not depend on them. But there\n        # might be such bad applications so keep this workaround for\n        # while.\n        if datapath.ofproto.OFP_VERSION < 0x04:\n            datapath.ports = msg.ports\n        else:\n            datapath.ports = {}\n\n        ofproto = datapath.ofproto\n        ofproto_parser = datapath.ofproto_parser\n        set_config = ofproto_parser.OFPSetConfig(\n            datapath, ofproto.OFPC_FRAG_NORMAL,\n            128  # TODO:XXX\n        )\n        datapath.send_msg(set_config)\n\n\n\t\t//version 1.0 = 0x01, 1.2 = 0x03, 1.3 = 0x04, 1.4 = 0x05\n        if datapath.ofproto.OFP_VERSION < 0x04:\n            self.logger.debug('move onto main mode')\n            ev.msg.datapath.set_state(MAIN_DISPATCHER) #这代码写的？？不是有获取好的datapath么\n        else:\n            port_desc = datapath.ofproto_parser.OFPPortDescStatsRequest(\n                datapath, 0) \n            datapath.send_msg(port_desc)\n\n**multipart\\_reply\\_handler**:port信息处理函数，之所以叫multipart是因为肯能一次消息没传完，记录port的信息，如果完成就进入MAIN\\_DISPATCHER状态\n\n    def multipart_reply_handler(self, ev):\n        msg = ev.msg\n        datapath = msg.datapath\n        for port in msg.body:\n            datapath.ports[port.port_no] = port\n\n        if msg.flags & datapath.ofproto.OFPMPF_REPLY_MORE:\n            return\n        self.logger.debug('move onto main mode')\n        ev.msg.datapath.set_state(MAIN_DISPATCHER)\n\n**echo\\_request\\_handler**函数：echo消息处理函数，向交换机发送echo消息\n\n\tdef echo_request_handler(self, ev):\n        msg = ev.msg\n        datapath = msg.datapath\n        echo_reply = datapath.ofproto_parser.OFPEchoReply(datapath)\n        echo_reply.xid = msg.xid\n        echo_reply.data = msg.data\n        datapath.send_msg(echo_reply)\n\n**error\\_msg\\_handler**：错误消息处理函数，只做了log\n\n\tdef error_msg_handler(self, ev):\n        msg = ev.msg\n        self.logger.debug('error msg ev %s type 0x%x code 0x%x %s',\n                          msg, msg.type, msg.code, utils.hex_array(msg.data))","mtime":1418484228000,"source":"_posts/ryu-source-analysis-4.md"},"sz85s27gealue1z0":{"_id":"sz85s27gealue1z0","content":"title: Ryu代码解析（五）\ndate: 2014/12/9 21:17:36 \ntags: \n- Ryu\n- Controller\ncategories: Ryu\n---\n\n## OpenFlowController类 ##\n该类位于ryu\\controller\\controller.py\n\nOpenFlowController类非常简单，它其实是作为OFPHandler类的一个线程存在的，而不是一个独立app。该类也没有OF协议相关的处理函数，那这个类究竟做什么呢？其实他的工作很简单，就是在著名的6633端口监听来自交换机的连接，并且建立与交换机之间的连接，并且在控制层面创建于其对应的dp类，连接建立后其余的工作就交给OFPHander类处理交换机发来的包了（从Hello包开始）。我们来详细看一下这个类的组成。\n<!--more-->\n**\\_\\_call\\_\\_函数**：这个函数是python的内置函数，该函数在类对象初始化时被自动的调用，从[上一篇博客中](http://geekwei.com/2014/12/04/ryu-source-analysis-4/)我们知道，OFPHandle在start函数中新建了OpenFlowController对象，此时就调用了__call__函数，该函数中调用server_loop函数。\n\n\n\t def __call__(self):\n        # LOG.debug('call')\n        self.server_loop()\n\n**server_loop函数**：该函数新建一个监听server，然后开始监听，就这么简单。只不过ryu使用了一个叫做[Gevent](http://www.gevent.org/)的轻量级高并发框架。博主不太了解该框架。我们只关注其功能，可以看到在函数中第一步就是新建一个StreamServer，在其参数中我们只关注datapath\\_connection\\_factory这个参数，其实他是一个函数句柄，当一个server成功接收一个来自交换机的连接时就调用该函数，后面会讲该函数。新建server之后，调用serve_forever，从函数名可知就是启动服务器开始服务。\n\n\tdef server_loop(self):\n        if CONF.ctl_privkey is not None and CONF.ctl_cert is not None:\n            if CONF.ca_certs is not None:\n                server = StreamServer((CONF.ofp_listen_host,\n                                       CONF.ofp_ssl_listen_port),\n                                      datapath_connection_factory,\n                                      keyfile=CONF.ctl_privkey,\n                                      certfile=CONF.ctl_cert,\n                                      cert_reqs=ssl.CERT_REQUIRED,\n                                      ca_certs=CONF.ca_certs,\n                                      ssl_version=ssl.PROTOCOL_TLSv1)\n            else:\n                server = StreamServer((CONF.ofp_listen_host,\n                                       CONF.ofp_ssl_listen_port),\n                                      datapath_connection_factory,\n                                      keyfile=CONF.ctl_privkey,\n                                      certfile=CONF.ctl_cert,\n                                      ssl_version=ssl.PROTOCOL_TLSv1)\n        else:\n            server = StreamServer((CONF.ofp_listen_host,\n                                   CONF.ofp_tcp_listen_port),\n                                  datapath_connection_factory)\n\n        # LOG.debug('loop')\n        server.serve_forever()\n\nOpenFlowController类就以上两个主要的函数，功能就是启动监听。\n\n接下来我们看一下上面提到的当成功建立与一台交换机的连接之后调用的函数。\n\n**datapath\\_connection\\_factory函数**： 该函数的参数是socket和address，是由streamserver建立与交换机连接之后传入的交换机的socket和address。然后就是一个麻烦的python特有语法 with ... as ...，是try...final的简易写法。在这里的流程是就是新建一个datapath(socket,address)，赋值给datapath，然后如果创建成功就执性try中的语句，如果创建都没成功就关闭它。执行try中的语句时，如果try中的语句出错就执行except中的语句，最后再执行contextlib.closing函数关闭新建的datapath。我们假设创建datapath是成功的，那么就执行datapath的serve函数(后面讲该函数)，有关datapath类的详细信息后面会介绍。可见当OpenFlowController的server每当成功连接一个交换机后，就会创建一个于其对应的datapath，以后与交换机的通信就通过该datapath。\n\n\tdef datapath_connection_factory(socket, address):\n\t    LOG.debug('connected socket:%s address:%s', socket, address)\n\t    with contextlib.closing(Datapath(socket, address)) as datapath:\n\t        try:\n\t            datapath.serve()\n\t        except:\n\t            # Something went wrong.\n\t            # Especially malicious switch can send malformed packet,\n\t            # the parser raise exception.\n\t            # Can we do anything more graceful?\n\t            if datapath.id is None:\n\t                dpid_str = \"%s\" % datapath.id\n\t            else:\n\t                dpid_str = dpid_to_str(datapath.id)\n\t            LOG.error(\"Error in the datapath %s from %s\", dpid_str, address)\n\t            raise\n\n## datapath类 ##\ndatapath类对象是与连接到控制器的交换机一一对应的，保存交换机的信息，并且接收和发送信息给交换机。我们来看一下这个类。\n\n**\\_\\_init\\_\\_函数**：初始化函数\n\n\tdef __init__(self, socket, address):\n        super(Datapath, self).__init__()\n\n        self.socket = socket //与交换机通信的套接字\n        self.socket.setsockopt(IPPROTO_TCP, TCP_NODELAY, 1)\n        self.address = address //IP地址\n        self.is_active = True //交换机状态：设置为活跃\n\n        # The limit is arbitrary. We need to limit queue size to\n        # prevent it from eating memory up\n        self.send_q = hub.Queue(16) //发送队列，最大16个包\n\n        self.xid = random.randint(0, self.ofproto.MAX_XID) //xid相当于消息的序列号，每发送一个消息曾 1\n        self.id = None  # datapath_id is unknown yet //id在之后的negotiation阶段获得\n        self.ports = None //现在还没有端口\n        self.flow_format = ofproto_v1_0.NXFF_OPENFLOW10\n        self.ofp_brick = ryu.base.app_manager.lookup_service_brick('ofp_event') //获取opf处理类，就是那个ofp_handler类\n        self.set_state(handler.HANDSHAKE_DISPATCHER) //将状态设置为握手阶段\n\n**close函数**：关闭datapath，将状态设置为.DEAD_DISPATCHE\n\n\tdef close(self):\n        self.set_state(handler.DEAD_DISPATCHER)\n\n**set\\_state函数**：设置交换机状态，生成状态改变事件，并通过send\\_event\\_to\\_observers函数（[之前有讲该函数](http://geekwei.com/2014/12/02/ryu-source-analysis-3/)）发送给关心该事件的类。\n\n\t def set_state(self, state):\n        self.state = state\n        ev = ofp_event.EventOFPStateChange(self) //生成状态改变事件\n        ev.state = state //将当前状态保存在事件中\n        self.ofp_brick.send_event_to_observers(ev, state) //发送给关心该事件的类\n\n**\\_recv\\_loop函数**：这是datapath中的主线程，负责接收来自交换机的消息。详细请看代码注释。\n\n\tdef _recv_loop(self):\n        buf = bytearray()\n        required_len = ofproto_common.OFP_HEADER_SIZE\n\n        count = 0\n        while self.is_active:\n            ret = self.socket.recv(required_len) //阻塞的接收来自交换机的包\n            if len(ret) == 0: //如果交换机断开了连接，recv函数会返回0\n                self.is_active = False //将交换机状态设置为false，那么主线程也就结束了\n                break\n            buf += ret\n            while len(buf) >= required_len: \n\t\t\t//while函数开始这里很有技巧，功能就是为了收到一个完整的包含包头和包体的消息\n\t\t\t//当第一次收到消息时，required\\_len=OFP\\_HEADER\\_SIZE,因此在上面的recv函数处设置的\n\t\t\t//缓冲区大小也是包头的大小，进入while循环后，执行下面这行函数，获取包头消息，这里我们关注\n\t\t\t//的是msg\\_len字段，表明该消息的总大小，然后接着把required\\_len设置为msg_len，如果我们\n\t\t\t//当前的buf中的信息长度不够msg\\_len，那么退出循环，继续接受剩余的信息。\n                (version, msg_type, msg_len, xid) = ofproto_parser.header(buf)\n                required_len = msg_len\n                if len(buf) < required_len:\n                    break\n\t\t\t//一旦函数到达这里，表明我们接收到了一个完整的消息，消息保存在buf中\n                msg = ofproto_parser.msg(self,\n                                         version, msg_type, msg_len, xid, buf) //获取消息体\n                # LOG.debug('queue msg %s cls %s', msg, msg.__class__)\n                if msg: //消息体不为空\n                    ev = ofp_event.ofp_msg_to_ev(msg) //获取消息中的事件\n\t\t\t\t\t//下面这行函数很重要，通过ofp\\_brick（该对象其实就是ofp\\_handler对象）将事件发送\n\t\t\t\t\t//关心该事件的app类，这里也体现出ryu文档中说的ofp_handler是将消息进行路由的功能\n                    self.ofp_brick.send_event_to_observers(ev, self.state)\n\n\t\t\t\t\t//定义一个函数dispatchers，该函数的作用是获取类x中对于事件ev的关心时间阶段\n                    dispatchers = lambda x: x.callers[ev.__class__].dispatchers\n\t\t\t\t\t//这里才是ofp\\_handler app获取处理函数的地方，从ofp\\_brick(opf\\_handler)中获取\n\t\t\t\t\t//事件ev的处理函数，并且datapath的当前的状态符合该处理函数定义的dispatchers\n                    handlers = [handler for handler in\n                                self.ofp_brick.get_handlers(ev) if\n                                self.state in dispatchers(handler)]\n                    for handler in handlers:\n                        handler(ev) //调用每个处理函数处理事件\n\n                buf = buf[required_len:] //从buf中去掉已经处理过的当前消息\n                required_len = ofproto_common.OFP_HEADER_SIZE //表明要开始接收新的包了\n\n                # We need to schedule other greenlets. Otherwise, ryu\n                # can't accept new switches or handle the existing\n                # switches. The limit is arbitrary. We need the better\n                # approach in the future.\n\t\t\t\t//当一个datapath处理了2048个消息后，主动sleep，让出cpu。还要主动休息一会儿？有待提高\n                count += 1\n                if count > 2048:\n                    count = 0\n                    hub.sleep(0)\n\n**\\_send_loop函数**：这是datapath另外一个线程，发送线程，将send\\_q中的消息全部发出去。如果发送失败，首先保存当前消息队列中的消息，然后将send\\_q设置为空，避免有新的消息加入，然后清空消息队列。\n\n\tdef _send_loop(self):\n        try:\n            while self.is_active:\n                buf = self.send_q.get()\n                self.socket.sendall(buf)\n        finally:\n            q = self.send_q\n            # first, clear self.send_q to prevent new references.\n            self.send_q = None\n            # there might be threads currently blocking in send_q.put().\n            # unblock them by draining the queue.\n            try:\n                while q.get(block=False):\n                    pass\n            except hub.QueueEmpty:\n                pass\n\n**send函数**：发送消息，将消息放在send\\_q中\n\n\tdef send(self, buf):\n        if self.send_q:\n            self.send_q.put(buf)\n\n\n**set\\_xid函数**：给msg设置xid\n\n\tdef set_xid(self, msg):\n        self.xid += 1\n        self.xid &= self.ofproto.MAX_XID\n        msg.set_xid(self.xid)\n        return self.xid\n\n**send\\_msg函数**：发送消息\n\n\t def send_msg(self, msg):\n        assert isinstance(msg, self.ofproto_parser.MsgBase)\n        if msg.xid is None:\n            self.set_xid(msg) //设置xid\n        msg.serialize() //将消息序列化\n        # LOG.debug('send_msg %s', msg)\n        self.send(msg.buf) //发送消息\n\n**serve函数**：这是新建datapath后，首先执行的主函数，负责启动datapath的主线程（\\_recv_loop）和副线程(\\_send_loop)\n\n\tdef serve(self):\n        send_thr = hub.spawn(self._send_loop) //启动副线程\n\n        # send hello message immediately\n        hello = self.ofproto_parser.OFPHello(self)\n        self.send_msg(hello) //建立连接后，控制器直接向交换机发送hello消息\n\n        try:\n            self._recv_loop() //执行主线程\n        finally:\n            hub.kill(send_thr)\n            hub.joinall([send_thr])\n\ndatapath还定义了一些方便发送常用消息的函数，如下，就不具体介绍了。\n\n\tdef send_packet_out(self, buffer_id=0xffffffff, in_port=None,\n                        actions=None, data=None):\n       \n    def send_flow_mod(self, rule, cookie, command, idle_timeout, hard_timeout,\n                      priority=None, buffer_id=0xffffffff,\n                      out_port=None, flags=0, actions=None):\n        \n    def send_flow_del(self, rule, cookie, out_port=None):\n        self.send_flow_mod(rule=rule, cookie=cookie,\n                           command=self.ofproto.OFPFC_DELETE,\n                           idle_timeout=0, hard_timeout=0, priority=0,\n                           out_port=out_port)\n\n    def send_delete_all_flows(self):\n        \n    def send_barrier(self):\n       \n    def send_nxt_set_flow_format(self, flow_format):\n        ","mtime":1418220882000,"source":"_posts/ryu-source-analysis-5.md"},"2ge6i6e3t2oi063c":{"_id":"2ge6i6e3t2oi063c","content":"title: Ryu代码解析（六）--未完待续\ndate: 2014/12/13 23:13:46 \ntags: \n- Ryu\n- Controller\ncategories: Ryu\n---\n\n## Ryu流程图 ##\n\n看Ryu代码有一段时间了，[Ryu控制器系列博客](http://geekwei.com/categories/Ryu/)前五部分基本已经把Ryu比较核心的几部分梳理清楚了，这才支持我可以总结下Ryu的总体流程图，今天花2个小时画完了这幅图，如下，目前还是比较粗略的，希望能给一起学习的朋友一些帮助。该图仅代表我当前对于Ryu的理解，也希望读者补充指正，博主也会随着对于代码理解的加深扩展修改该图。\n\n![Ryu Flow Chart](/img/ryusourceflowchart.jpg)\n","mtime":1418525079000,"source":"_posts/ryu-source-analysis-6.md"}}}